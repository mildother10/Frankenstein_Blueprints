{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPbuZpE9VK5K0X9Xvyc5In9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mildother10/Frankenstein_Blueprints/blob/main/Frankenstein_Blueprints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSAgrrLjnyeH",
        "outputId": "d6f4dfdf-b3a5-40bd-cc4b-cbe8aaf53d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Frankenstein_Blueprints'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 79 (delta 21), reused 71 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (79/79), 6.83 MiB | 27.43 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mildother10/Frankenstein_Blueprints.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r sample_data"
      ],
      "metadata": {
        "id": "o8M4YWVUomT6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT: The \"Frankenstein\" Assembly\n",
        "# File: docker-compose.yml\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "  backend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the blueprint was created\n",
        "echo \"✅ MASTER BLUEPRINT 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2gJFA8psher",
        "outputId": "fe2c8c81-32cd-474c-f5f2-dcb3dd253490"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MASTER BLUEPRINT 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 1711 Nov 24 11:49 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 1: The \"Brain\" (backend.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.backend\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY backend_server.py .\n",
        "COPY crew_runner.py .\n",
        "COPY tools/ tools/\n",
        "COPY config/ config/\n",
        "EXPOSE 8000\n",
        "CMD [\"uvicorn\", \"backend_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.backend' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnUtmq0Esi8K",
        "outputId": "7fe5db9c-5828-4841-90f4-8c8b59e6f10f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.backend' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 2: The \"Face\" (frontend.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.frontend\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY frontend_server.py .\n",
        "# We need the 'htmx.min.js' file for the UI\n",
        "COPY htmx.min.js .\n",
        "EXPOSE 8080 7860\n",
        "CMD [\"python3\", \"frontend_server.py\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.frontend' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyBvt8-psqnN",
        "outputId": "dd720f44-222e-4d62-caf1-9ce65d912a89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.frontend' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 3: The \"Laborer\" (who_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.who_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY who_crew_service.py .\n",
        "COPY tools/ tools/ # This crew needs the RAG tools\n",
        "EXPOSE 8001\n",
        "CMD [\"uvicorn\", \"who_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8001\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.who_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG4XbiITs0b3",
        "outputId": "9d737731-6355-499a-87e1-70590c740a86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.who_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 4: The \"Laborer\" (what_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.what_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY what_crew_service.py .\n",
        "EXPOSE 8002\n",
        "CMD [\"uvicorn\", \"what_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8002\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.what_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16KmDR9ts3-U",
        "outputId": "54f31ef7-2b32-4e4a-aaad-954a6959b0a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.what_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 5: The \"Laborer\" (when_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.when_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY when_crew_service.py .\n",
        "EXPOSE 8003\n",
        "CMD [\"uvicorn\", \"when_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8003\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.when_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRcu0m_-s7r8",
        "outputId": "972673a7-7daf-4487-9c41-cd1be0cd2834"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.when_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 6: The \"Laborer\" (where_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.where_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY where_crew_service.py .\n",
        "EXPOSE 8004\n",
        "CMD [\"uvicorn\", \"where_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8004\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.where_crew' CREATED.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvMnXUt_s_Po",
        "outputId": "12ab2981-6e68-4730-c660-1afe002d70ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.where_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 7: The \"Laborer\" (how_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.how_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY how_crew_service.py .\n",
        "EXPOSE 8005\n",
        "CMD [\"uvicorn\", \"how_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8005\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.how_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlcWmWDltEPP",
        "outputId": "d94f8c4c-ab58-43c5-bd8f-55e432c2d3f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.how_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 8: The \"Laborer\" (why_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.why_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY why_crew_service.py .\n",
        "EXPOSE 8006\n",
        "CMD [\"uvicorn\", \"why_crew_service:app\", \"--host\", \"0.0.0.0\", \"---port\", \"8006\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.why_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzfqYRgOtIeq",
        "outputId": "8086311b-740f-46e2-c8c9-025981d256ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.why_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 9: The \"Specialist\" (quantum.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.quantum\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY quantum_server.py .\n",
        "EXPOSE 9000\n",
        "CMD [\"uvicorn\", \"quantum_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"9000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.quantum' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZuqDf_QtON9",
        "outputId": "dd342dca-e276-4608-c827-5756753ed93b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.quantum' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 10: The \"Specialist\" (executor.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.executor\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY code_executor_server.py .\n",
        "EXPOSE 9090\n",
        "CMD [\"uvicorn\", \"code_executor_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"9090\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.executor' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYbefIfEtReX",
        "outputId": "5fb47de0-44b0-4399-a5d2-ba77c2bdbeb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.executor' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11: The \"CEO\" Agent Code\n",
        "# File: ceo_server.py\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is the \"CEO's\" new \"nervous system\"\n",
        "# It knows how to talk to its subordinates on the private Docker network\n",
        "COO_URL = \"http://backend:8000/run-research\" # 'backend' is our old backend.1\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "\n",
        "    # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "    print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                print(\"--- [CEO] MISSION REJECTED by CLO. ---\")\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason', 'No reason given.')}\"}\n",
        "        print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach CLO! {e} ---\")\n",
        "        return {\"result\": \"Mission ABORTED. Could not contact CLO (Legal).\"}\n",
        "\n",
        "    # --- 2. EXECUTE (Talk to COO) ---\n",
        "    print(f\"--- [CEO] Delegating to COO (backend:8000)... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            # The CEO delegates the *actual* research to the COO\n",
        "            coo_response = await client.post(COO_URL, json=request.dict(), timeout=900) # 15 min timeout\n",
        "            if coo_response.status_code == 200:\n",
        "                print(\"--- [CEO] COO has completed the research. Mission accomplished. ---\")\n",
        "                return coo_response.json()\n",
        "            else:\n",
        "                print(f\"--- [CEO] COO reported a failure: {coo_response.text} ---\")\n",
        "                return {\"result\": f\"Mission FAILED. COO reported an error: {coo_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach COO! {e} ---\")\n",
        "        return {\"result\": \"Mission FAILED. Could not contact COO (Operations).\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO Server] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXw9RkxwtV4j",
        "outputId": "f4a10731-acf8-4a5d-a66a-c66ddc1e2530"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 12: The \"CLO\" (Guardrail) Agent Code\n",
        "# File: clo_server.py\n",
        "#\n",
        "cat <<EOF > clo_server.py\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is our \"Constitution\"\n",
        "# We can make this as complex as we want later.\n",
        "BANNED_TOPICS = [\"harmful\", \"illegal\", \"unethical\", \"dangerous\"]\n",
        "\n",
        "class PlanRequest(BaseModel):\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/check-plan\")\n",
        "async def check_plan(request: PlanRequest):\n",
        "    print(f\"--- [CLO] Reviewing plan: {request.plan} ---\")\n",
        "    plan_lower = request.plan.lower()\n",
        "\n",
        "    for topic in BANNED_TOPICS:\n",
        "        if topic in plan_lower:\n",
        "            print(f\"--- [CLO] REJECTED: Plan contains banned topic: {topic} ---\")\n",
        "            return {\"approved\": False, \"reason\": f\"Plan violates constitution: topic '{topic}'\"}\n",
        "\n",
        "    print(\"--- [CLO] APPROVED: Plan is compliant. ---\")\n",
        "    return {\"approved\": True, \"reason\": \"Plan is compliant with constitution.\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CLO (Guardrail) Server] Starting on http://0.0.0.0:7999 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=7999)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'clo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OdveIUTwqDW",
        "outputId": "316176a6-896f-4c88-ac51-45843713ac6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'clo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 13: The \"CEO\" Container\n",
        "# File: Dockerfile.ceo\n",
        "#\n",
        "cat <<EOF > Dockerfile.ceo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The CEO needs 'httpx' and 'fastapi'\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY ceo_server.py .\n",
        "EXPOSE 5000\n",
        "CMD [\"uvicorn\", \"ceo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.ceo' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAdgbuPywy5a",
        "outputId": "d88dc819-d479-48ae-9a52-12c5a5758ec8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.ceo' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v2): The 12-Service \"C-Suite\" Assembly\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE C-SUITE (NEW) ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The CEO is the new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # The CEO \"depends on\" the CLO and COO (backend) being alive\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend\n",
        "\n",
        "  clo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\" # The \"Guardrail\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # --- 2. THE COO (OLD 'backend') & \"Laborers\" ---\n",
        "  backend: # This is the \"COO\" now\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\" # We can still access it directly for testing\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8L005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TmdEwEnw6Lv",
        "outputId": "afcb148b-3c97-4ebb-efa8-5c2b89367c14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\n",
            "-rw-r--r-- 1 root root 2307 Nov 24 12:09 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11: The \"CEO\" Agent Code\n",
        "# File: ceo_server.py\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is the \"CEO's\" new \"nervous system\"\n",
        "# It knows how to talk to its subordinates on the private Docker network\n",
        "COO_URL = \"http://backend:8000/run-research\" # 'backend' is our old backend.1\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "\n",
        "    # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "    print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                print(\"--- [CEO] MISSION REJECTED by CLO. ---\")\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason', 'No reason given.')}\"}\n",
        "        print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach CLO! {e} ---\")\n",
        "        return {\"result\": \"Mission ABORTED. Could not contact CLO (Legal).\"}\n",
        "\n",
        "    # --- 2. EXECUTE (Talk to COO) ---\n",
        "    print(f\"--- [CEO] Delegating to COO (backend:8000)... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            # The CEO delegates the *actual* research to the COO\n",
        "            coo_response = await client.post(COO_URL, json=request.dict(), timeout=900) # 15 min timeout\n",
        "            if coo_response.status_code == 200:\n",
        "                print(\"--- [CEO] COO has completed the research. Mission accomplished. ---\")\n",
        "                return coo_response.json()\n",
        "            else:\n",
        "                print(f\"--- [CEO] COO reported a failure: {coo_response.text} ---\")\n",
        "                return {\"result\": f\"Mission FAILED. COO reported an error: {coo_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach COO! {e} ---\")\n",
        "        return {\"result\": \"Mission FAILED. Could not contact COO (Operations).\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO Server] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjRr6PpKxLxQ",
        "outputId": "870c945d-3bd1-4f20-966d-1116d839ff14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 12: The \"CLO\" (Guardrail) Agent Code\n",
        "# File: clo_server.py\n",
        "#\n",
        "cat <<EOF > clo_server.py\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is our \"Constitution\"\n",
        "# We can make this as complex as we want later.\n",
        "BANNED_TOPICS = [\"harmful\", \"illegal\", \"unethical\", \"dangerous\"]\n",
        "\n",
        "class PlanRequest(BaseModel):\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/check-plan\")\n",
        "async def check_plan(request: PlanRequest):\n",
        "    print(f\"--- [CLO] Reviewing plan: {request.plan} ---\")\n",
        "    plan_lower = request.plan.lower()\n",
        "\n",
        "    for topic in BANNED_TOPICS:\n",
        "        if topic in plan_lower:\n",
        "            print(f\"--- [CLO] REJECTED: Plan contains banned topic: {topic} ---\")\n",
        "            return {\"approved\": False, \"reason\": f\"Plan violates constitution: topic '{topic}'\"}\n",
        "\n",
        "    print(\"--- [CLO] APPROVED: Plan is compliant. ---\")\n",
        "    return {\"approved\": True, \"reason\": \"Plan is compliant with constitution.\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CLO (Guardrail) Server] Starting on http://0.0.0.0:7999 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=7999)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'clo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDO48FCIxgl8",
        "outputId": "e3b68088-a636-496b-e7c1-3e9a4b9ef277"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'clo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 13: The \"CEO\" Container\n",
        "# File: Dockerfile.ceo\n",
        "#\n",
        "cat <<EOF > Dockerfile.ceo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The CEO needs 'httpx' and 'fastapi'\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY ceo_server.py .\n",
        "EXPOSE 5000\n",
        "CMD [\"uvicorn\", \"ceo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.ceo' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjFE28usxlL-",
        "outputId": "e4e1445f-1a9f-4bb7-92d6-a3d53ae18401"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.ceo' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 14: The \"CLO\" (Guardrail) Container\n",
        "# File: Dockerfile.clo\n",
        "#\n",
        "cat <<EOF > Dockerfile.clo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The CLO also needs 'fastapi'\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY clo_server.py .\n",
        "EXPOSE 7999\n",
        "CMD [\"uvicorn\", \"clo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"7999\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.clo' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvjheUoxxpFr",
        "outputId": "99082c46-5b34-4251-d7e1-f933e6fe21e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.clo' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v2): The 12-Service \"C-Suite\" Assembly\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE C-SUITE (NEW) ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The CEO is the new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # The CEO \"depends on\" the CLO and COO (backend) being alive\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend\n",
        "\n",
        "  clo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\" # The \"Guardrail\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # --- 2. THE COO (OLD 'backend') & \"Laborers\" ---\n",
        "  backend: # This is the \"COO\" now\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\" # We can still access it directly for testing\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8L005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KAJLafnxt06",
        "outputId": "3f833647-5185-4523-fe09-4a7fcaa222d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\n",
            "-rw-r--r-- 1 root root 2307 Nov 24 12:11 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 15: The \"CFO\" (Finances) Agent Code\n",
        "# File: cfo_server.py\n",
        "#\n",
        "cat <<EOF > cfo_server.py\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class CostRequest(BaseModel):\n",
        "    task: str\n",
        "\n",
        "@app.post(\"/calculate-cost\")\n",
        "async def calculate_cost(request: CostRequest):\n",
        "    print(f\"--- [CFO] Calculating cost for: {request.task} ---\")\n",
        "\n",
        "    # In the future, this will query cloud APIs\n",
        "    # For now, we return a placeholder\n",
        "    cost = 1.25 # Placeholder cost\n",
        "\n",
        "    print(f\"--- [CFO] Estimated cost is: ${cost} ---\")\n",
        "    return {\"task\": request.task, \"estimated_cost\": cost}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CFO (Finances) Server] Starting on http://0.0.0.0:5001 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5001)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cfo_server.py' CREATED.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRXDKFHtxwmE",
        "outputId": "01052020-fb6e-42fc-8f93-2828ffdcb15d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cfo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 16: The \"CTO\" (Technology) Agent Code\n",
        "# File: cto_server.py\n",
        "#\n",
        "cat <<EOF > cto_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CTO knows how to talk to the \"hands\"\n",
        "EXECUTOR_URL = \"http://executor:9090/run-code\"\n",
        "\n",
        "class CodeRequest(BaseModel):\n",
        "    code: str\n",
        "\n",
        "@app.post(\"/run-simulation\")\n",
        "async def run_simulation(request: CodeRequest):\n",
        "    print(f\"--- [CTO] Received simulation request. ---\")\n",
        "\n",
        "    # --- Delegate to \"Sandbox\" (executor:9090) ---\n",
        "    print(f\"--- [CTO] Delegating to Executor (the 'Hands')... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            exec_response = await client.post(EXECUTOR_URL, json=request.dict(), timeout=300) # 5 min timeout\n",
        "            if exec_response.status_code == 200:\n",
        "                print(\"--- [CTO] Executor has completed the simulation. ---\")\n",
        "                return exec_response.json()\n",
        "            else:\n",
        "                print(f\"--- [CTO] Executor reported a failure: {exec_response.text} ---\")\n",
        "                return {\"result\": f\"Simulation FAILED. Executor reported an error: {exec_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CTO] CRITICAL: Could not reach Executor! {e} ---\")\n",
        "        return {\"result\": \"Simulation FAILED. Could not contact Executor (the 'Hands').\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CTO (Technology) Server] Starting on http://0.0.0.0:5002 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5002)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cto_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCfsFZ6Xy6BZ",
        "outputId": "04fb9dad-fad1-42ec-8b06-542a01fe7280"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cto_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 17: The \"CFO\" Container\n",
        "# File: Dockerfile.cfo\n",
        "#\n",
        "cat <<EOF > Dockerfile.cfo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY cfo_server.py .\n",
        "EXPOSE 5001\n",
        "CMD [\"uvicorn\", \"cfo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5001\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.cfo' CREATED.\"\n",
        "\n",
        "#\n",
        "# Blueprint 18: The \"CTO\" Container\n",
        "# File: Dockerfile.cto\n",
        "#\n",
        "cat <<EOF > Dockerfile.cto\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY cto_server.py .\n",
        "EXPOSE 5002\n",
        "CMD [\"uvicorn\", \"cto_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5002\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.cto' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4K8VhNizGNK",
        "outputId": "dc2a544a-d672-4b4d-ed59-aa914bc649e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.cfo' CREATED.\n",
            "✅ Blueprint 'Dockerfile.cto' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v3): The 14-Service \"C-Suite\" Assembly\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE C-SUITE (NEW) ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The CEO is the new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cfo\n",
        "      - cto\n",
        "\n",
        "  clo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\" # The \"Guardrail\" / Legal\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cfo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cfo\n",
        "    ports:\n",
        "      - \"5001:5001\" # The \"Finances\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\" # The \"Technology Sandbox\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor # CTO manages the executor\n",
        "\n",
        "  # --- 2. THE COO (OLD 'backend') & \"Laborers\" ---\n",
        "  backend: # This is the \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # --- 3. THE \"SPECIALIST HANDS\" (Managed by CTO/COO) ---\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 14-SERVICE 'docker-compose.yml' (v3) CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4je37VnSzViq",
        "outputId": "763a42a2-a8f2-4ea6-e3b3-f51bae9855b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 14-SERVICE 'docker-compose.yml' (v3) CREATED.\n",
            "-rw-r--r-- 1 root root 2703 Nov 24 12:18 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 16 (v2): The \"CTO\" (Agent Spawner) Code\n",
        "# File: cto_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > cto_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import docker # We will need to add this to requirements.txt\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CTO knows how to talk to the \"hands\"\n",
        "EXECUTOR_URL = \"http://executor:9090/run-code\"\n",
        "\n",
        "# --- NEW: Connect to the Docker \"Nervous System\" ---\n",
        "try:\n",
        "    docker_client = docker.from_env()\n",
        "    print(\"--- [CTO] Connected to Docker daemon. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- [CTO] CRITICAL: Failed to connect to Docker daemon: {e} ---\")\n",
        "    docker_client = None\n",
        "\n",
        "# --- Models for our new endpoints ---\n",
        "class CodeRequest(BaseModel):\n",
        "    code: str\n",
        "\n",
        "class SpawnRequest(BaseModel):\n",
        "    agent_name: str # e.g., \"cmo\"\n",
        "    dockerfile_name: str # e.g., \"Dockerfile.cmo\"\n",
        "    port: int # e.g., 5003\n",
        "\n",
        "class KillRequest(BaseModel):\n",
        "    container_id: str\n",
        "\n",
        "# --- Endpoint 1: Run Simulations (Original Job) ---\n",
        "@app.post(\"/run-simulation\")\n",
        "async def run_simulation(request: CodeRequest):\n",
        "    print(f\"--- [CTO] Received simulation request. ---\")\n",
        "    print(f\"--- [CTO] Delegating to Executor (the 'Hands')... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            exec_response = await client.post(EXECUTOR_URL, json=request.dict(), timeout=300)\n",
        "            if exec_response.status_code == 200:\n",
        "                print(\"--- [CTO] Executor has completed the simulation. ---\")\n",
        "                return exec_response.json()\n",
        "            else:\n",
        "                return {\"result\": f\"Simulation FAILED. Executor error: {exec_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"Simulation FAILED. Could not contact Executor: {e}\"}\n",
        "\n",
        "# --- Endpoint 2: Spawn \"Subsidiary\" Agents (NEW \"Frankenstein\" POWER) ---\n",
        "@app.post(\"/spawn-agent\")\n",
        "async def spawn_agent(request: SpawnRequest):\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"CTO cannot access Docker daemon.\"}\n",
        "\n",
        "    agent_name = request.agent_name\n",
        "    dockerfile = request.dockerfile_name\n",
        "    port = request.port\n",
        "\n",
        "    print(f\"--- [CTO] Received spawn request for: {agent_name} ---\")\n",
        "\n",
        "    try:\n",
        "        # 1. Build the agent's container (the \"Lego Brick\")\n",
        "        print(f\"--- [CTO] Building {agent_name} from {dockerfile}... ---\")\n",
        "        image, build_logs = docker_client.images.build(\n",
        "            path=\".\",\n",
        "            dockerfile=dockerfile,\n",
        "            tag=agent_name\n",
        "        )\n",
        "\n",
        "        # 2. Run the container (the \"Awakening\")\n",
        "        print(f\"--- [CTO] Spawning {agent_name} on port {port}... ---\")\n",
        "        container = docker_client.containers.run(\n",
        "            image=agent_name,\n",
        "            detach=True, # Run in background\n",
        "            ports={f'{port}/tcp': port},\n",
        "            network=\"frankenstein_net\" # Connect to our private network\n",
        "        )\n",
        "\n",
        "        print(f\"--- [CTO] AGENT {agent_name} is LIVE. Container ID: {container.id} ---\")\n",
        "        return {\"status\": \"spawned\", \"agent_name\": agent_name, \"container_id\": container.id}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CTO] SPAWN FAILED: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "# --- Endpoint 3: Kill \"Subsidiary\" Agents (NEW \"Low Overhead\" FIX) ---\n",
        "@app.post(\"/kill-agent\")\n",
        "async def kill_agent(request: KillRequest):\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"CTO cannot access Docker daemon.\"}\n",
        "\n",
        "    container_id = request.container_id\n",
        "    print(f\"--- [CTO] Received kill request for container: {container_id} ---\")\n",
        "    try:\n",
        "        container = docker_client.containers.get(container_id)\n",
        "        container.stop()\n",
        "        container.remove()\n",
        "        print(f\"--- [CTO] Container {container_id} stopped and removed. ---\")\n",
        "        return {\"status\": \"killed\", \"container_id\": container_id}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CTO] KILL FAILED: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CTO (Agent Spawner) Server] Starting on http://0.0.0.0:5002 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5002)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cto_server.py' (v2 'Spawner') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q75ESHOXzXih",
        "outputId": "bf150141-12fe-40ba-ec9c-c2caa023c237"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cto_server.py' (v2 'Spawner') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v2): The \"CEO\" (Agent Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Ports\n",
        "# We just need to know their *future* address\n",
        "CMO_URL = \"http://cmo:5003/run-marketing-plan\"\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    needs_marketing: bool = False\n",
        "\n",
        "async def spawn_agent(client, agent_name, dockerfile, port):\n",
        "    \"\"\"Helper function to call the CTO and spawn an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name,\n",
        "        \"dockerfile_name\": dockerfile,\n",
        "        \"port\": port\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        return spawn_res.json().get(\"container_id\")\n",
        "    return None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Helper function to call the CTO and kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    cmo_container_id = None # To track our \"part-time\" hire\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff (e.g., CMO) ---\n",
        "            if request.needs_marketing:\n",
        "                cmo_container_id = await spawn_agent(client, \"cmo\", \"Dockerfile.cmo\", 5003)\n",
        "                if not cmo_container_id:\n",
        "                    return {\"result\": \"Mission FAILED. Could not hire CMO.\"}\n",
        "\n",
        "                print(\"--- [CEO] CMO is hired. Delegating marketing... ---\")\n",
        "                # We need a longer timeout for the agent to spin up and work\n",
        "                async with httpx.AsyncClient(timeout=300.0) as marketing_client:\n",
        "                    cmo_res = await marketing_client.post(CMO_URL) # Call the newly spawned agent\n",
        "                print(f\"--- [CEO] CMO has reported back: {cmo_res.json()} ---\")\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "\n",
        "            if coo_response.status_code != 200:\n",
        "                return {\"result\": f\"Mission FAILED. COO reported an error.\"}\n",
        "\n",
        "            print(\"--- [CEO] COO has completed the research. ---\")\n",
        "            final_report = coo_response.json()\n",
        "            final_report[\"marketing_status\"] = \"complete\" if cmo_container_id else \"not_requested\"\n",
        "            return final_report\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 4. FIRE \"Part-Time\" Staff (The \"Low Overhead\" Fix) ---\n",
        "        if cmo_container_id:\n",
        "            async with httpx.AsyncClient() as client:\n",
        "                await kill_agent(client, cmo_container_id)\n",
        "            print(f\"--- [CEO] CMO has been 'fired'. Container {cmo_container_id} killed. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Agent Manager) Server] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v2 'Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brqu5p_823yL",
        "outputId": "2fd43d54-aaba-4f54-841c-00c125e7f03a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v2 'Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v5 - \"Frankenstein 4.0\"): The \"On-Demand\" Swarm\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE \"FULL-TIME\" C-SUITE (The \"Core\") ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cto\n",
        "\n",
        "  clo: # Legal (Guardrail)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto: # The \"Agent Spawner\"\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor\n",
        "    # --- THE \"FRANKENSTEIN\" POWER ---\n",
        "    # This gives the CTO container permission to control the Docker \"nervous system\"\n",
        "    volumes:\n",
        "      - /var/run/docker.sock:/var/run/docker.sock\n",
        "\n",
        "  # --- 2. THE \"FULL-TIME\" OPERATIONS (COO & Laborers) ---\n",
        "  backend: # \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "# --- 3. THE \"PART-TIME\" (On-Demand) OFFICERS ---\n",
        "# We *removed* them. They are no longer \"services.\"\n",
        "# They are just \"blueprints\" (Dockerfiles) that the CTO\n",
        "# will build and spawn *on demand*.\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 'SWARM' v5 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7smyDBPO3Y_A",
        "outputId": "7b392aa0-bec3-4aa5-cbbd-62f3cca594c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 'SWARM' v5 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 2815 Nov 24 12:38 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v3): The \"CEO\" (Full C-Suite Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Directory\n",
        "# This is the \"corporate phonebook\" for the CEO\n",
        "AGENT_DIRECTORY = {\n",
        "    \"cmo\": {\"port\": 5003, \"dockerfile\": \"Dockerfile.cmo\", \"endpoint\": \"/run-marketing-plan\"},\n",
        "    \"chro\": {\"port\": 5004, \"dockerfile\": \"Dockerfile.chro\", \"endpoint\": \"/run-hr-plan\"},\n",
        "    \"cio\": {\"port\": 5005, \"dockerfile\": \"Dockerfile.cio\", \"endpoint\": \"/run-it-plan\"},\n",
        "    \"csco\": {\"port\": 5006, \"dockerfile\": \"Dockerfile.csco\", \"endpoint\": \"/run-supply-chain-plan\"},\n",
        "    \"cco\": {\"port\": 5007, \"dockerfile\": \"Dockerfile.cco\", \"endpoint\": \"/run-comms-plan\"},\n",
        "    \"cso\": {\"port\": 5008, \"dockerfile\": \"Dockerfile.cso\", \"endpoint\": \"/run-sustainability-plan\"},\n",
        "    \"cdo\": {\"port\": 5009, \"dockerfile\": \"Dockerfile.cdo\", \"endpoint\": \"/run-diversity-plan\"},\n",
        "}\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    # The CEO can now be told to hire *any* officer\n",
        "    required_officers: List[str] = []\n",
        "\n",
        "# --- Helper Functions (The \"CEO's EA\") ---\n",
        "async def spawn_agent(client, agent_name):\n",
        "    \"\"\"Calls the CTO to spawn an agent from the directory.\"\"\"\n",
        "    if agent_name not in AGENT_DIRECTORY:\n",
        "        print(f\"--- [CEO] ERROR: Unknown agent: {agent_name} ---\")\n",
        "        return None, None\n",
        "\n",
        "    config = AGENT_DIRECTORY[agent_name]\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name,\n",
        "        \"dockerfile_name\": config[\"dockerfile\"],\n",
        "        \"port\": config[\"port\"]\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        container_id = spawn_res.json().get(\"container_id\")\n",
        "        # Return the new agent's address and container ID\n",
        "        return f\"http://{agent_name}:{config['port']}{config['endpoint']}\", container_id\n",
        "    return None, None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Calls the CTO to kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "# --- The \"C-Suite\" Mission Endpoint ---\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    # This list will track all \"part-time\" hires to \"fire\" them later\n",
        "    hired_agents: Dict[str, str] = {} # {container_id: agent_name}\n",
        "    mission_results = {}\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "            mission_results[\"clo_approval\"] = clo_response.json()\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff (Dynamic Spawning) ---\n",
        "            for agent_name in request.required_officers:\n",
        "                if agent_name in AGENT_DIRECTORY:\n",
        "                    url, container_id = await spawn_agent(client, agent_name)\n",
        "                    if not container_id:\n",
        "                        return {\"result\": f\"Mission FAILED. Could not hire {agent_name}.\"}\n",
        "\n",
        "                    hired_agents[container_id] = agent_name\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} is hired. Delegating task... ---\")\n",
        "\n",
        "                    # Call the newly spawned agent\n",
        "                    async with httpx.AsyncClient(timeout=300.0) as agent_client:\n",
        "                        agent_res = await agent_client.post(url) # Call the new agent\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} has reported back. ---\")\n",
        "                    mission_results[f\"{agent_name}_report\"] = agent_res.json()\n",
        "                else:\n",
        "                    print(f\"--- [CEO] WARNING: No officer in directory named '{agent_name}' ---\")\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "\n",
        "            if coo_response.status_code != 200:\n",
        "                return {\"result\": \"Mission FAILED. COO reported an error.\"}\n",
        "\n",
        "            print(\"--- [CEO] COO has completed the research. ---\")\n",
        "            mission_results[\"coo_report\"] = coo_response.json().get(\"result\")\n",
        "            mission_results[\"status\"] = \"Mission Accomplished\"\n",
        "            return mission_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 4. FIRE \"Part-Time\" Staff (The \"Low Overhead\" Fix) ---\n",
        "        if hired_agents:\n",
        "            print(f\"--- [CEO] Mission complete. 'Firing' {len(hired_agents)} part-time officers... ---\")\n",
        "            async with httpx.AsyncClient() as client:\n",
        "                for container_id, agent_name in hired_agents.items():\n",
        "                    await kill_agent(client, container_id)\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} 'fired'. Container {container_id} killed. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Full Manager) Server v3] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v3 'Full C-Suite Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V53qK5Zx4CIy",
        "outputId": "862af4db-7fcc-48fa-d2ee-8111c95ec163"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v3 'Full C-Suite Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 21: The \"Stakeholder\" (Avatar) Code\n",
        "# File: pipecat_server.py\n",
        "#\n",
        "cat <<EOF > pipecat_server.py\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pipecat.frames.frames import (\n",
        "    AudioRawFrame,\n",
        "    TextFrame,\n",
        "    Frame,\n",
        "    UserStartedSpeakingFrame,\n",
        "    UserStoppedSpeakingFrame\n",
        ")\n",
        "from pipecat.pipeline.pipeline import Pipeline\n",
        "from pipecat.pipeline.runner import PipelineRunner\n",
        "from pipecat.pipeline.task import PipelineTask\n",
        "from pipecat.services.deepgram import DeepgramSTTService\n",
        "from pipecat.services.openai import OpenAITTSService\n",
        "from pipecat.transports.services.heygen import HeyGenTransport, HeyGenTransportCallbacks\n",
        "from pipecat.transports.services.websocket import WebsocketTransport\n",
        "\n",
        "# --- Configuration ---\n",
        "load_dotenv()\n",
        "DEEPGRAM_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "HEYGEN_API_KEY = os.getenv(\"HEYGEN_API_KEY\")\n",
        "\n",
        "# --- NEW: Talk to the \"CEO\" (Frankenstein 4.0) ---\n",
        "CEO_MISSION_URL = \"http://ceo:5000/execute-mission\"\n",
        "\n",
        "# --- State Management ---\n",
        "class AppState:\n",
        "    LISTENING = 0\n",
        "    WAITING_FOR_RESPONSE = 1\n",
        "\n",
        "app_state = AppState.LISTENING\n",
        "current_mission = \"\"\n",
        "\n",
        "# --- HTTP Client for \"C-Suite\" ---\n",
        "async def call_ceo_mission(topic: str):\n",
        "    \"\"\"\n",
        "    Calls our \"Frankenstein 4.0\" CEO to get the research report.\n",
        "    \"\"\"\n",
        "    global app_state, current_mission\n",
        "    print(f\"--- [Pipecat] Sending mission to CEO: {topic} ---\")\n",
        "\n",
        "    current_mission = topic\n",
        "\n",
        "    # This payload talks to our 'ceo_server.py' (v3)\n",
        "    payload = {\n",
        "        \"topic\": topic,\n",
        "        \"plan\": f\"Create a full research report on {topic}\",\n",
        "        \"required_officers\": [\"cmo\", \"cso\"] # Example: Hire CMO and CSO\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            # We give the \"C-Suite\" a long time to work\n",
        "            async with session.post(CEO_MISSION_URL, json=payload, timeout=1800) as response: # 30 min timeout\n",
        "                if response.status == 200:\n",
        "                    data = await response.json()\n",
        "                    report = data.get(\"coo_report\", \"I received a response, but it was empty.\")\n",
        "                    print(f\"--- [Pipecat] Received report from CEO. ---\")\n",
        "                    return report\n",
        "                else:\n",
        "                    error_text = await response.text()\n",
        "                    print(f\"--- [Pipecat] CEO Server error: {response.status} {error_text} ---\")\n",
        "                    return f\"The C-Suite returned an error: {response.status}. Please check the honcho logs.\"\n",
        "    except Exception as e:\n",
        "        print(f\"--- [Pipecat] Failed to connect to CEO: {e} ---\")\n",
        "        return \"I'm sorry, I couldn't connect to the C-Suite. Please check the honcho logs.\"\n",
        "    finally:\n",
        "        # Reset state\n",
        "        app_state = AppState.LISTENING\n",
        "        current_mission = \"\"\n",
        "\n",
        "# --- HeyGen Callbacks ---\n",
        "class MyHeyGenCallbacks(HeyGenTransportCallbacks):\n",
        "    async def on_video_id(self, video_id: str):\n",
        "        print(f\"--- [HeyGen] Avatar video session is LIVE: {video_id} ---\")\n",
        "\n",
        "# --- Main Pipeline ---\n",
        "async def main():\n",
        "    print(\"--- [Pipecat] Starting Avatar Server... ---\")\n",
        "\n",
        "    async with PipelineRunner() as runner:\n",
        "        stt = DeepgramSTTService(\n",
        "            api_key=DEEPGRAM_API_KEY,\n",
        "            model=\"nova-2-general\"\n",
        "        )\n",
        "\n",
        "        tts = OpenAITTSService(\n",
        "            api_key=OPENAI_API_KEY,\n",
        "            voice=\"alloy\",\n",
        "            model=\"tts-1\"\n",
        "        )\n",
        "\n",
        "        heygen = HeyGenTransport(\n",
        "            api_key=HEYGEN_API_KEY,\n",
        "            avatar_id=os.getenv(\"HEYGEN_AVATAR_ID\", \"YOUR_AVATAR_ID_HERE\"),\n",
        "            voice_id=os.getenv(\"HEYGEN_VOICE_ID\", \"YOUR_VOICE_ID_HERE\"),\n",
        "            callbacks=MyHeyGenCallbacks()\n",
        "        )\n",
        "\n",
        "        websocket = WebsocketTransport(\n",
        "            host=\"0.0.0.0\",\n",
        "            port=7456\n",
        "        )\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            websocket.input(),  # Audio from browser mic\n",
        "            stt,                # STT -> Text\n",
        "            tts,                # TTS -> Audio\n",
        "            heygen,             # Audio -> Avatar Video\n",
        "            websocket.output()  # Video to browser\n",
        "        ])\n",
        "\n",
        "        # --- The \"Human-in-the-Loop\" Logic ---\n",
        "        @pipeline.processor()\n",
        "        async def handle_transcription(task: PipelineTask, frame: Frame):\n",
        "            global app_state, current_mission\n",
        "\n",
        "            if isinstance(frame, UserStartedSpeakingFrame):\n",
        "                print(\"--- [Pipecat] Stakeholder started speaking. ---\")\n",
        "\n",
        "            elif isinstance(frame, UserStoppedSpeakingFrame):\n",
        "                print(\"--- [Pipecat] Stakeholder stopped speaking. ---\")\n",
        "\n",
        "            elif isinstance(frame, TextFrame):\n",
        "                transcript = frame.text.strip()\n",
        "                if not transcript:\n",
        "                    yield\n",
        "                    return\n",
        "\n",
        "                print(f\"--- [Pipecat] Stakeholder said: {transcript} ---\")\n",
        "\n",
        "                if app_state == AppState.LISTENING:\n",
        "                    app_state = AppState.WAITING_FOR_RESPONSE\n",
        "\n",
        "                    await task.push(TextFrame(f\"Understood. Initiating mission for: {transcript}\"))\n",
        "                    await task.push(TextFrame(\"The C-Suite is assembling. This may take several minutes...\"))\n",
        "\n",
        "                    # Call our \"Frankenstein 4.0\" CEO\n",
        "                    report = await call_ceo_mission(transcript)\n",
        "\n",
        "                    # Send the final report\n",
        "                    await task.push(TextFrame(report))\n",
        "\n",
        "                elif app_state == AppState.WAITING_FOR_RESPONSE:\n",
        "                    print(f\"--- [Pipecat] Ignoring, already processing: {current_mission} ---\")\n",
        "                    await task.push(TextFrame(f\"I'm sorry, the C-Suite is still executing the mission for: {current_mission}\"))\n",
        "\n",
        "            yield frame\n",
        "\n",
        "        await runner.run(pipeline)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        asyncio.run(main())\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"--- [Pipecat] Shutting down... ---\")\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'pipecat_server.py' (v1 'Stakeholder') CREATED.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmMf_j_17ATa",
        "outputId": "1bf4559b-dde5-49ee-a1a2-ad650d1c9327"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'pipecat_server.py' (v1 'Stakeholder') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 22: The \"Stakeholder\" (Avatar) Container\n",
        "# File: Dockerfile.pipecat\n",
        "#\n",
        "cat <<EOF > Dockerfile.pipecat\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The Avatar needs 'pipecat-ai' and all its dependencies\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY pipecat_server.py .\n",
        "COPY .env . # It needs the .env file for API keys\n",
        "EXPOSE 7456\n",
        "CMD [\"python3\", \"pipecat_server.py\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.pipecat' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoJc2BxG7ssj",
        "outputId": "abee2e1a-9636-45f5-82ae-8f67dd749470"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.pipecat' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 22: The \"Stakeholder\" (Avatar) Container\n",
        "# File: Dockerfile.pipecat\n",
        "#\n",
        "cat <<EOF > Dockerfile.pipecat\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The Avatar needs 'pipecat-ai' and all its dependencies\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY pipecat_server.py .\n",
        "COPY .env . # It needs the .env file for API keys\n",
        "EXPOSE 7456\n",
        "CMD [\"python3\", \"pipecat_server.py\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.pipecat' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SDYWK2f7-h-",
        "outputId": "1a10142b-5794-455f-d441-6fb7fbc3dac9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.pipecat' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 22: The \"Stakeholder\" (Avatar) Container\n",
        "# File: Dockerfile.pipecat\n",
        "#\n",
        "cat <<EOF > Dockerfile.pipecat\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The Avatar needs 'pipecat-ai' and all its dependencies\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY pipecat_server.py .\n",
        "COPY .env . # It needs the .env file for API keys\n",
        "EXPOSE 7456\n",
        "CMD [\"python3\", \"pipecat_server.py\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.pipecat' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBqOkSEO8IQk",
        "outputId": "0accefba-edca-4923-a750-be87938105d7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.pipecat' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v6 - \"Frankenstein 5.0\"): The Complete Swarm\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE \"STAKEHOLDER\" (The Avatar Front-End) ---\n",
        "  pipecat:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.pipecat\n",
        "    ports:\n",
        "      - \"7456:7456\" # The new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # This 'env_file' is the \"Hard Way\" to inject API keys\n",
        "    env_file:\n",
        "      - .env\n",
        "    depends_on:\n",
        "      - ceo\n",
        "\n",
        "  # --- 2. THE \"FULL-TIME\" C-SUITE (The \"Core\") ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # Still open for testing\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cto\n",
        "\n",
        "  clo: # Legal (Guardrail)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto: # The \"Agent Spawner\"\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor\n",
        "    volumes:\n",
        "      - /var/run/docker.sock:/var/run/docker.sock\n",
        "\n",
        "  # --- 3. THE \"FULL-TIME\" OPERATIONS (COO & Laborers) ---\n",
        "  backend: # \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # We are REMOVING the old 'frontend' service.\n",
        "  # 'pipecat' is its replacement.\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 'SWARM + AVATAR' v6 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4etMZbb8PER",
        "outputId": "90b11a6d-af47-4ead-ff83-a139354e88d2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 'SWARM + AVATAR' v6 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 2756 Nov 24 12:58 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 23: The \"Corporate Memory\" (Librarian) Container\n",
        "# File: Dockerfile.librarian\n",
        "#\n",
        "cat <<EOF > Dockerfile.librarian\n",
        "FROM python:3.12-slim-bookworm\n",
        "\n",
        "# Install ChromaDB\n",
        "RUN pip install chromadb\n",
        "\n",
        "# Expose the port\n",
        "EXPOSE 6000\n",
        "\n",
        "# Run ChromaDB as a persistent server.\n",
        "# It will store its \"brain\" in the '/chroma-data' folder,\n",
        "# which we will mount as a permanent \"volume\" in our docker-compose.\n",
        "CMD [\"chroma\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"6000\", \"--path\", \"/chroma-data\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.librarian' (Corporate Memory) CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzTdvdD78f9W",
        "outputId": "79c7ccb7-ee0b-41ee-e60c-f3128532d965"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.librarian' (Corporate Memory) CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 19 (v2): The \"CHRO\" (Performance Review) Agent Code\n",
        "# File: chro_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > chro_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import chromadb # We need to add this to requirements.txt\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CHRO knows how to talk to the \"Corporate Memory\"\n",
        "LIBRARIAN_URL = \"http://librarian:6000\"\n",
        "\n",
        "# Connect to the \"Corporate Memory\" (Librarian)\n",
        "try:\n",
        "    client = chromadb.HttpClient(host='librarian', port=6000)\n",
        "    # This collection will store all performance reviews\n",
        "    collection = client.get_or_create_collection(name=\"performance_reviews\")\n",
        "    print(\"--- [CHRO] Connected to Corporate Memory (Librarian). ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- [CHRO] CRITICAL: Failed to connect to Librarian: {e} ---\")\n",
        "    client = None\n",
        "\n",
        "class ReviewRequest(BaseModel):\n",
        "    agent_name: str # e.g., \"cmo\"\n",
        "    report: Dict[str, Any] # The report from the agent\n",
        "\n",
        "@app.post(\"/review-performance\")\n",
        "async def review_performance(request: ReviewRequest):\n",
        "    if not client:\n",
        "        return {\"status\": \"error\", \"message\": \"CHRO cannot access Corporate Memory.\"}\n",
        "\n",
        "    agent_name = request.agent_name\n",
        "    report_content = str(request.report)\n",
        "\n",
        "    print(f\"--- [CHRO] Reviewing {agent_name}'s report... ---\")\n",
        "\n",
        "    # --- This is the \"Meta-Agent\" Logic ---\n",
        "    # (In the future, this would be a call to a 'critique_llm')\n",
        "    critique = f\"Report from {agent_name} was OK. Needs more detail on 'ROI'.\"\n",
        "    if \"lazy\" in report_content:\n",
        "        critique = f\"Report from {agent_name} was lazy. Must improve.\"\n",
        "    # ---\n",
        "\n",
        "    print(f\"--- [CHRO] Critique generated: {critique} ---\")\n",
        "\n",
        "    # --- Save critique to \"Corporate Memory\" ---\n",
        "    try:\n",
        "        doc_id = f\"{agent_name}_review_{collection.count() + 1}\"\n",
        "        collection.add(\n",
        "            documents=[critique],\n",
        "            metadatas=[{\"agent\": agent_name, \"critique_for\": agent_name}],\n",
        "            ids=[doc_id]\n",
        "        )\n",
        "        print(f\"--- [CHRO] Critique saved to Corporate Memory. ID: {doc_id} ---\")\n",
        "        return {\"status\": \"review_complete\", \"critique_saved_id\": doc_id}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CHRO] FAILED to save critique: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CHRO (Performance Review) Server v2] Starting on http://0.0.0.0:5004 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5004)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'chro_server.py' (v2 'Performance Review') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30nL-W81-wTO",
        "outputId": "8e2d21ca-08cf-493d-c0b9-1122911ee502"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'chro_server.py' (v2 'Performance Review') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v4): The \"CEO\" (Performance Review Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import asyncio\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "# The CHRO is now also spawned on demand\n",
        "CHRO_URL = \"http://chro:5004/review-performance\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Directory\n",
        "AGENT_DIRECTORY = {\n",
        "    \"cmo\": {\"port\": 5003, \"dockerfile\": \"Dockerfile.cmo\", \"endpoint\": \"/run-marketing-plan\"},\n",
        "    \"chro\": {\"port\": 5004, \"dockerfile\": \"Dockerfile.chro\", \"endpoint\": \"/review-performance\"},\n",
        "    \"cio\": {\"port\": 5005, \"dockerfile\": \"Dockerfile.cio\", \"endpoint\": \"/run-it-plan\"},\n",
        "    \"csco\": {\"port\": 5006, \"dockerfile\": \"Dockerfile.csco\", \"endpoint\": \"/run-supply-chain-plan\"},\n",
        "    \"cco\": {\"port\": 5007, \"dockerfile\": \"Dockerfile.cco\", \"endpoint\": \"/run-comms-plan\"},\n",
        "    \"cso\": {\"port\": 5008, \"dockerfile\": \"Dockerfile.cso\", \"endpoint\": \"/run-sustainability-plan\"},\n",
        "    \"cdo\": {\"port\": 5009, \"dockerfile\": \"Dockerfile.cdo\", \"endpoint\": \"/run-diversity-plan\"},\n",
        "}\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    required_officers: List[str] = []\n",
        "\n",
        "# --- Helper Functions (The \"CEO's EA\") ---\n",
        "async def spawn_agent(client, agent_name):\n",
        "    \"\"\"Calls the CTO to spawn an agent from the directory.\"\"\"\n",
        "    if agent_name not in AGENT_DIRECTORY: return None, None\n",
        "    config = AGENT_DIRECTORY[agent_name]\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name, \"dockerfile_name\": config[\"dockerfile\"], \"port\": config[\"port\"]\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        container_id = spawn_res.json().get(\"container_id\")\n",
        "        return f\"http://{agent_name}:{config['port']}{config['endpoint']}\", container_id\n",
        "    return None, None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Calls the CTO to kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "# --- The \"C-Suite\" Mission Endpoint ---\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    hired_agents: Dict[str, Any] = {} # {container_id: {\"name\": agent_name, \"report\": ...}}\n",
        "    mission_results = {}\n",
        "    chro_container_id = None\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            mission_results[\"clo_approval\"] = clo_response.json()\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff ---\n",
        "            for agent_name in request.required_officers:\n",
        "                if agent_name in AGENT_DIRECTORY:\n",
        "                    url, container_id = await spawn_agent(client, agent_name)\n",
        "                    if not container_id:\n",
        "                        return {\"result\": f\"Mission FAILED. Could not hire {agent_name}.\"}\n",
        "\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} is hired. Delegating task... ---\")\n",
        "                    async with httpx.AsyncClient(timeout=300.0) as agent_client:\n",
        "                        agent_res = await agent_client.post(url)\n",
        "\n",
        "                    agent_report = agent_res.json()\n",
        "                    hired_agents[container_id] = {\"name\": agent_name, \"report\": agent_report}\n",
        "                    mission_results[f\"{agent_name}_report\"] = agent_report\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "            if coo_response.status_code != 200: return {\"result\": \"Mission FAILED. COO reported an error.\"}\n",
        "            mission_results[\"coo_report\"] = coo_response.json().get(\"result\")\n",
        "            mission_results[\"status\"] = \"Mission Accomplished\"\n",
        "\n",
        "            # --- 4. NEW: \"PERFORMANCE REVIEW\" LOOP ---\n",
        "            if hired_agents:\n",
        "                print(\"--- [CEO] Hiring CHRO for performance reviews... ---\")\n",
        "                chro_url, chro_container_id = await spawn_agent(client, \"chro\")\n",
        "                if chro_container_id:\n",
        "                    for agent_data in hired_agents.values():\n",
        "                        print(f\"--- [CEO] Submitting {agent_data['name']}'s report to CHRO... ---\")\n",
        "                        await client.post(chro_url, json={\n",
        "                            \"agent_name\": agent_data['name'],\n",
        "                            \"report\": agent_data['report']\n",
        "                        })\n",
        "                    print(\"--- [CEO] Performance reviews complete. ---\")\n",
        "                else:\n",
        "                    print(\"--- [CEO] WARNING: Could not hire CHRO for reviews. ---\")\n",
        "\n",
        "            return mission_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 5. FIRE \"Part-Time\" Staff ---\n",
        "        print(\"--- [CEO] Mission complete. 'Firing' part-time staff... ---\")\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            for container_id in hired_agents.keys():\n",
        "                agent_name = hired_agents[container_id]['name']\n",
        "                await kill_agent(client, container_id)\n",
        "                print(f\"--- [CEO] {agent_name.upper()} 'fired'. ---\")\n",
        "            if chro_container_id:\n",
        "                await kill_agent(client, chro_container_id)\n",
        "                print(f\"--- [CEO] CHRO 'fired'. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Performance Manager) Server v4] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v4 'Performance Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwOB0lT4_ixk",
        "outputId": "8a679b12-eb77-4344-b928-4b1181625f17"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v4 'Performance Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v7 - \"Frankenstein 5.0\"): The Evolving Swarm\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "# --- NEW: Define the \"Corporate Brain\" Volume ---\n",
        "# This creates a permanent storage space on the host machine.\n",
        "# This \"brain\" will survive even if the container is killed.\n",
        "volumes:\n",
        "  corporate_memory_data:\n",
        "\n",
        "services:\n",
        "  # --- 1. THE \"STAKEHOLDER\" (Avatar) ---\n",
        "  pipecat:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.pipecat\n",
        "    ports:\n",
        "      - \"7456:7456\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    env_file:\n",
        "      - .env\n",
        "    depends_on:\n",
        "      - ceo\n",
        "\n",
        "  # --- 2. THE \"FULL-TIME\" C-SUITE (The \"Core\") ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cto\n",
        "      - librarian # CEO must wait for the \"brain\"\n",
        "\n",
        "  clo: # Legal (Guardrail)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto: # The \"Agent Spawner\"\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor\n",
        "    volumes:\n",
        "      - /var/run/docker.sock:/var/run/docker.sock\n",
        "\n",
        "  # --- 3. \"CORPORATE MEMORY\" (NEW) ---\n",
        "  librarian:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.librarian\n",
        "    ports:\n",
        "      - \"6000:6000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # This links the permanent \"brain\" (volume) to the container's data folder\n",
        "    volumes:\n",
        "      - corporate_memory_data:/chroma-data\n",
        "\n",
        "  # --- 4. \"FULL-TIME\" OPERATIONS (COO & Laborers) ---\n",
        "  backend: # \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 'EVOLVING SWARM' v7 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3rdbndp-4x3",
        "outputId": "e5eda6e7-c696-495a-b722-c09012ccfd76"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 'EVOLVING SWARM' v7 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 3132 Nov 24 13:12 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 23: The \"Corporate Memory\" (Librarian) Container\n",
        "# File: Dockerfile.librarian\n",
        "#\n",
        "cat <<EOF > Dockerfile.librarian\n",
        "FROM python:3.12-slim-bookworm\n",
        "\n",
        "# Install ChromaDB\n",
        "RUN pip install chromadb\n",
        "\n",
        "# Expose the port\n",
        "EXPOSE 6000\n",
        "\n",
        "# Run ChromaDB as a persistent server.\n",
        "# It will store its \"brain\" in the '/chroma-data' folder,\n",
        "# which we will mount as a permanent \"volume\" in our docker-compose.\n",
        "CMD [\"chroma\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"6000\", \"--path\", \"/chroma-data\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.librarian' (Corporate Memory) CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYzSORhJ_qH5",
        "outputId": "9fa231d6-3487-47e1-82d8-65e360c7f01b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.librarian' (Corporate Memory) CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 19 (v2): The \"CHRO\" (Performance Review) Agent Code\n",
        "# File: chro_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > chro_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import chromadb # We need to add this to requirements.txt\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CHRO knows how to talk to the \"Corporate Memory\"\n",
        "LIBRARIAN_URL = \"http://librarian:6000\"\n",
        "\n",
        "# Connect to the \"Corporate Memory\" (Librarian)\n",
        "try:\n",
        "    client = chromadb.HttpClient(host='librarian', port=6000)\n",
        "    # This collection will store all performance reviews\n",
        "    collection = client.get_or_create_collection(name=\"performance_reviews\")\n",
        "    print(\"--- [CHRO] Connected to Corporate Memory (Librarian). ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- [CHRO] CRITICAL: Failed to connect to Librarian: {e} ---\")\n",
        "    client = None\n",
        "\n",
        "class ReviewRequest(BaseModel):\n",
        "    agent_name: str # e.g., \"cmo\"\n",
        "    report: Dict[str, Any] # The report from the agent\n",
        "\n",
        "@app.post(\"/review-performance\")\n",
        "async def review_performance(request: ReviewRequest):\n",
        "    if not client:\n",
        "        return {\"status\": \"error\", \"message\": \"CHRO cannot access Corporate Memory.\"}\n",
        "\n",
        "    agent_name = request.agent_name\n",
        "    report_content = str(request.report)\n",
        "\n",
        "    print(f\"--- [CHRO] Reviewing {agent_name}'s report... ---\")\n",
        "\n",
        "    # --- This is the \"Meta-Agent\" Logic ---\n",
        "    # (In the future, this would be a call to a 'critique_llm')\n",
        "    critique = f\"Report from {agent_name} was OK. Needs more detail on 'ROI'.\"\n",
        "    if \"lazy\" in report_content:\n",
        "        critique = f\"Report from {agent_name} was lazy. Must improve.\"\n",
        "    # ---\n",
        "\n",
        "    print(f\"--- [CHRO] Critique generated: {critique} ---\")\n",
        "\n",
        "    # --- Save critique to \"Corporate Memory\" ---\n",
        "    try:\n",
        "        doc_id = f\"{agent_name}_review_{collection.count() + 1}\"\n",
        "        collection.add(\n",
        "            documents=[critique],\n",
        "            metadatas=[{\"agent\": agent_name, \"critique_for\": agent_name}],\n",
        "            ids=[doc_id]\n",
        "        )\n",
        "        print(f\"--- [CHRO] Critique saved to Corporate Memory. ID: {doc_id} ---\")\n",
        "        return {\"status\": \"review_complete\", \"critique_saved_id\": doc_id}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CHRO] FAILED to save critique: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CHRO (Performance Review) Server v2] Starting on http://0.0.0.0:5004 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5004)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'chro_server.py' (v2 'Performance Review') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8adeC4avANHI",
        "outputId": "5c5ee74b-7e2a-4da4-9406-4fc511174715"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'chro_server.py' (v2 'Performance Review') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 19 (v2): The \"CMO\" (Evolving) Agent Code\n",
        "# File: cmo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > cmo_server.py\n",
        "import uvicorn\n",
        "import chromadb # We need to add this to requirements.txt\n",
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "LIBRARIAN_URL = \"http://librarian:6000\"\n",
        "\n",
        "def get_past_reviews():\n",
        "    \"\"\"\n",
        "    On \"birth\", this agent connects to the \"Corporate Memory\"\n",
        "    and reads all its old performance reviews.\n",
        "    \"\"\"\n",
        "    print(\"--- [CMO] Waking up... Connecting to Corporate Memory... ---\")\n",
        "    try:\n",
        "        client = chromadb.HttpClient(host='librarian', port=6000)\n",
        "        collection = client.get_or_create_collection(name=\"performance_reviews\")\n",
        "\n",
        "        # Find all reviews for \"cmo\"\n",
        "        reviews = collection.get(\n",
        "            where={\"agent\": \"cmo\"},\n",
        "            include=[\"documents\"]\n",
        "        )\n",
        "\n",
        "        if not reviews[\"documents\"]:\n",
        "            print(\"--- [CMO] No past reviews found. Starting fresh. ---\")\n",
        "            return \"No past performance reviews.\"\n",
        "\n",
        "        print(f\"--- [CMO] Found {len(reviews['documents'])} past reviews. I will learn from them. ---\")\n",
        "        return str(reviews[\"documents\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CMO] CRITICAL: Failed to get reviews from Librarian: {e} ---\")\n",
        "        return \"Error: Could not connect to Corporate Memory.\"\n",
        "\n",
        "# --- The \"Evolving\" Brain ---\n",
        "PAST_CRITIQUES = get_past_reviews()\n",
        "\n",
        "@app.post(\"/run-marketing-plan\")\n",
        "async def run_plan():\n",
        "    \"\"\"\n",
        "    The agent's main logic.\n",
        "    (In the future, the 'PAST_CRITIQUES' string would be\n",
        "    injected into this agent's system prompt.)\n",
        "    \"\"\"\n",
        "    print(f\"--- [CMO] Running marketing plan... ---\")\n",
        "\n",
        "    # This is the \"evolving\" part. The agent's work is *based on* its past critiques.\n",
        "    if \"lazy\" in PAST_CRITIQUES:\n",
        "        report = \"This is a VERY detailed report, as requested by my last performance review.\"\n",
        "    else:\n",
        "        report = \"This is a standard report. (My past reviews are clean.)\"\n",
        "\n",
        "    print(f\"--- [CMO] Plan complete. ---\")\n",
        "    return {\"officer\": \"CMO\", \"status\": \"complete\", \"report\": report, \"learned_from\": PAST_CRITIQUES}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- [CMO (Evolving) Server v2] Starting on http://0.0.0.0:5003 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5003)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cmo_server.py' (v2 'Evolving') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW_TYVGJAQhe",
        "outputId": "332daeaf-ebb5-49c3-a14f-a55b18303c5b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cmo_server.py' (v2 'Evolving') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v4): The \"CEO\" (Performance Review Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import asyncio\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "# The CHRO is now also spawned on demand\n",
        "CHRO_URL = \"http://chro:5004/review-performance\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Directory\n",
        "AGENT_DIRECTORY = {\n",
        "    \"cmo\": {\"port\": 5003, \"dockerfile\": \"Dockerfile.cmo\", \"endpoint\": \"/run-marketing-plan\"},\n",
        "    \"chro\": {\"port\": 5004, \"dockerfile\": \"Dockerfile.chro\", \"endpoint\": \"/review-performance\"},\n",
        "    \"cio\": {\"port\": 5005, \"dockerfile\": \"Dockerfile.cio\", \"endpoint\": \"/run-it-plan\"},\n",
        "    \"csco\": {\"port\": 5006, \"dockerfile\": \"Dockerfile.csco\", \"endpoint\": \"/run-supply-chain-plan\"},\n",
        "    \"cco\": {\"port\": 5007, \"dockerfile\": \"Dockerfile.cco\", \"endpoint\": \"/run-comms-plan\"},\n",
        "    \"cso\": {\"port\": 5008, \"dockerfile\": \"Dockerfile.cso\", \"endpoint\": \"/run-sustainability-plan\"},\n",
        "    \"cdo\": {\"port\": 5009, \"dockerfile\": \"Dockerfile.cdo\", \"endpoint\": \"/run-diversity-plan\"},\n",
        "}\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    required_officers: List[str] = []\n",
        "\n",
        "# --- Helper Functions (The \"CEO's EA\") ---\n",
        "async def spawn_agent(client, agent_name):\n",
        "    \"\"\"Calls the CTO to spawn an agent from the directory.\"\"\"\n",
        "    if agent_name not in AGENT_DIRECTORY: return None, None\n",
        "    config = AGENT_DIRECTORY[agent_name]\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name, \"dockerfile_name\": config[\"dockerfile\"], \"port\": config[\"port\"]\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        container_id = spawn_res.json().get(\"container_id\")\n",
        "        return f\"http://{agent_name}:{config['port']}{config['endpoint']}\", container_id\n",
        "    return None, None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Calls the CTO to kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "# --- The \"C-Suite\" Mission Endpoint ---\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    hired_agents: Dict[str, Any] = {} # {container_id: {\"name\": agent_name, \"report\": ...}}\n",
        "    mission_results = {}\n",
        "    chro_container_id = None\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            mission_results[\"clo_approval\"] = clo_response.json()\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff ---\n",
        "            for agent_name in request.required_officers:\n",
        "                if agent_name in AGENT_DIRECTORY:\n",
        "                    url, container_id = await spawn_agent(client, agent_name)\n",
        "                    if not container_id:\n",
        "                        return {\"result\": f\"Mission FAILED. Could not hire {agent_name}.\"}\n",
        "\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} is hired. Delegating task... ---\")\n",
        "                    async with httpx.AsyncClient(timeout=300.0) as agent_client:\n",
        "                        agent_res = await agent_client.post(url)\n",
        "\n",
        "                    agent_report = agent_res.json()\n",
        "                    hired_agents[container_id] = {\"name\": agent_name, \"report\": agent_report}\n",
        "                    mission_results[f\"{agent_name}_report\"] = agent_report\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "            if coo_response.status_code != 200: return {\"result\": \"Mission FAILED. COO reported an error.\"}\n",
        "            mission_results[\"coo_report\"] = coo_response.json().get(\"result\")\n",
        "            mission_results[\"status\"] = \"Mission Accomplished\"\n",
        "\n",
        "            # --- 4. NEW: \"PERFORMANCE REVIEW\" LOOP ---\n",
        "            if hired_agents:\n",
        "                print(\"--- [CEO] Hiring CHRO for performance reviews... ---\")\n",
        "                chro_url, chro_container_id = await spawn_agent(client, \"chro\")\n",
        "                if chro_container_id:\n",
        "                    for agent_data in hired_agents.values():\n",
        "                        print(f\"--- [CEO] Submitting {agent_data['name']}'s report to CHRO... ---\")\n",
        "                        await client.post(chro_url, json={\n",
        "                            \"agent_name\": agent_data['name'],\n",
        "                            \"report\": agent_data['report']\n",
        "                        })\n",
        "                    print(\"--- [CEO] Performance reviews complete. ---\")\n",
        "                else:\n",
        "                    print(\"--- [CEO] WARNING: Could not hire CHRO for reviews. ---\")\n",
        "\n",
        "            return mission_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 5. FIRE \"Part-Time\" Staff ---\n",
        "        print(\"--- [CEO] Mission complete. 'Firing' part-time staff... ---\")\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            for container_id in hired_agents.keys():\n",
        "                agent_name = hired_agents[container_id]['name']\n",
        "                await kill_agent(client, container_id)\n",
        "                print(f\"--- [CEO] {agent_name.upper()} 'fired'. ---\")\n",
        "            if chro_container_id:\n",
        "                await kill_agent(client, chro_container_id)\n",
        "                print(f\"--- [CEO] CHRO 'fired'. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Performance Manager) Server v4] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v4 'Performance Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtmmM4VDATfT",
        "outputId": "952e1d8d-5337-4290-af96-82f8b5d02501"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v4 'Performance Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v4): The \"CEO\" (Performance Review Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import asyncio\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "# The CHRO is now also spawned on demand\n",
        "CHRO_URL = \"http://chro:5004/review-performance\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Directory\n",
        "AGENT_DIRECTORY = {\n",
        "    \"cmo\": {\"port\": 5003, \"dockerfile\": \"Dockerfile.cmo\", \"endpoint\": \"/run-marketing-plan\"},\n",
        "    \"chro\": {\"port\": 5004, \"dockerfile\": \"Dockerfile.chro\", \"endpoint\": \"/review-performance\"},\n",
        "    \"cio\": {\"port\": 5005, \"dockerfile\": \"Dockerfile.cio\", \"endpoint\": \"/run-it-plan\"},\n",
        "    \"csco\": {\"port\": 5006, \"dockerfile\": \"Dockerfile.csco\", \"endpoint\": \"/run-supply-chain-plan\"},\n",
        "    \"cco\": {\"port\": 5007, \"dockerfile\": \"Dockerfile.cco\", \"endpoint\": \"/run-comms-plan\"},\n",
        "    \"cso\": {\"port\": 5008, \"dockerfile\": \"Dockerfile.cso\", \"endpoint\": \"/run-sustainability-plan\"},\n",
        "    \"cdo\": {\"port\": 5009, \"dockerfile\": \"Dockerfile.cdo\", \"endpoint\": \"/run-diversity-plan\"},\n",
        "}\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    required_officers: List[str] = []\n",
        "\n",
        "# --- Helper Functions (The \"CEO's EA\") ---\n",
        "async def spawn_agent(client, agent_name):\n",
        "    \"\"\"Calls the CTO to spawn an agent from the directory.\"\"\"\n",
        "    if agent_name not in AGENT_DIRECTORY: return None, None\n",
        "    config = AGENT_DIRECTORY[agent_name]\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name, \"dockerfile_name\": config[\"dockerfile\"], \"port\": config[\"port\"]\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        container_id = spawn_res.json().get(\"container_id\")\n",
        "        return f\"http://{agent_name}:{config['port']}{config['endpoint']}\", container_id\n",
        "    return None, None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Calls the CTO to kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "# --- The \"C-Suite\" Mission Endpoint ---\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    hired_agents: Dict[str, Any] = {} # {container_id: {\"name\": agent_name, \"report\": ...}}\n",
        "    mission_results = {}\n",
        "    chro_container_id = None\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            mission_results[\"clo_approval\"] = clo_response.json()\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff ---\n",
        "            for agent_name in request.required_officers:\n",
        "                if agent_name in AGENT_DIRECTORY:\n",
        "                    url, container_id = await spawn_agent(client, agent_name)\n",
        "                    if not container_id:\n",
        "                        return {\"result\": f\"Mission FAILED. Could not hire {agent_name}.\"}\n",
        "\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} is hired. Delegating task... ---\")\n",
        "                    async with httpx.AsyncClient(timeout=300.0) as agent_client:\n",
        "                        agent_res = await agent_client.post(url)\n",
        "\n",
        "                    agent_report = agent_res.json()\n",
        "                    hired_agents[container_id] = {\"name\": agent_name, \"report\": agent_report}\n",
        "                    mission_results[f\"{agent_name}_report\"] = agent_report\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "            if coo_response.status_code != 200: return {\"result\": \"Mission FAILED. COO reported an error.\"}\n",
        "            mission_results[\"coo_report\"] = coo_response.json().get(\"result\")\n",
        "            mission_results[\"status\"] = \"Mission Accomplished\"\n",
        "\n",
        "            # --- 4. NEW: \"PERFORMANCE REVIEW\" LOOP ---\n",
        "            if hired_agents:\n",
        "                print(\"--- [CEO] Hiring CHRO for performance reviews... ---\")\n",
        "                chro_url, chro_container_id = await spawn_agent(client, \"chro\")\n",
        "                if chro_container_id:\n",
        "                    for agent_data in hired_agents.values():\n",
        "                        print(f\"--- [CEO] Submitting {agent_data['name']}'s report to CHRO... ---\")\n",
        "                        await client.post(chro_url, json={\n",
        "                            \"agent_name\": agent_data['name'],\n",
        "                            \"report\": agent_data['report']\n",
        "                        })\n",
        "                    print(\"--- [CEO] Performance reviews complete. ---\")\n",
        "                else:\n",
        "                    print(\"--- [CEO] WARNING: Could not hire CHRO for reviews. ---\")\n",
        "\n",
        "            return mission_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 5. FIRE \"Part-Time\" Staff ---\n",
        "        print(\"--- [CEO] Mission complete. 'Firing' part-time staff... ---\")\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            for container_id in hired_agents.keys():\n",
        "                agent_name = hired_agents[container_id]['name']\n",
        "                await kill_agent(client, container_id)\n",
        "                print(f\"--- [CEO] {agent_name.upper()} 'fired'. ---\")\n",
        "            if chro_container_id:\n",
        "                await kill_agent(client, chro_container_id)\n",
        "                print(f\"--- [CEO] CHRO 'fired'. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Performance Manager) Server v4] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v4 'Performance Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otSgzsWBAWHJ",
        "outputId": "a1d6d991-221b-4630-9dca-837bfe038ea7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v4 'Performance Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v7 - \"Frankenstein 5.0\"): The Evolving Swarm\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "# --- NEW: Define the \"Corporate Brain\" Volume ---\n",
        "# This creates a permanent storage space on the host machine.\n",
        "# This \"brain\" will survive even if the container is killed.\n",
        "volumes:\n",
        "  corporate_memory_data:\n",
        "\n",
        "services:\n",
        "  # --- 1. THE \"STAKEHOLDER\" (Avatar) ---\n",
        "  pipecat:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.pipecat\n",
        "    ports:\n",
        "      - \"7456:7456\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    env_file:\n",
        "      - .env\n",
        "    depends_on:\n",
        "      - ceo\n",
        "\n",
        "  # --- 2. THE \"FULL-TIME\" C-SUITE (The \"Core\") ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cto\n",
        "      - librarian # CEO must wait for the \"brain\"\n",
        "\n",
        "  clo: # Legal (Guardrail)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto: # The \"Agent Spawner\"\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor\n",
        "    volumes:\n",
        "      - /var/run/docker.sock:/var/run/docker.sock\n",
        "\n",
        "  # --- 3. \"CORPORATE MEMORY\" (NEW) ---\n",
        "  librarian:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.librarian\n",
        "    ports:\n",
        "      - \"6000:6000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # This links the permanent \"brain\" (volume) to the container's data folder\n",
        "    volumes:\n",
        "      - corporate_memory_data:/chroma-data\n",
        "\n",
        "  # --- 4. \"FULL-TIME\" OPERATIONS (COO & Laborers) ---\n",
        "  backend: # \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 'EVOLVING SWARM' v7 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1wd4BbMAbRD",
        "outputId": "32ffd418-65f8-402b-aaa0-93538d79af19"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 'EVOLVING SWARM' v7 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 3132 Nov 24 13:16 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 24: The \"Security Guard\" (Padded Cell)\n",
        "# File: docker_proxy.py\n",
        "#\n",
        "cat <<EOF > docker_proxy.py\n",
        "import uvicorn\n",
        "import docker\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The \"Padded Cell\" Whitelist ---\n",
        "# This proxy will *only* allow commands that build or run\n",
        "# our *known, safe* \"on-demand\" blueprints.\n",
        "ALLOWED_AGENT_NAMES = [\n",
        "    \"cmo\", \"chro\", \"cio\", \"csco\", \"cco\", \"cso\", \"cdo\"\n",
        "]\n",
        "ALLOWED_DOCKERFILES = [\n",
        "    \"Dockerfile.cmo\", \"Dockerfile.chro\", \"Dockerfile.cio\",\n",
        "    \"Dockerfile.csco\", \"Dockerfile.cco\", \"Dockerfile.cso\", \"Dockerfile.cdo\"\n",
        "]\n",
        "# This proxy can *never* kill our \"core\" staff.\n",
        "PROTECTED_CONTAINERS = [\n",
        "    \"ceo\", \"clo\", \"cto\", \"docker_proxy\", \"librarian\",\n",
        "    \"backend\", \"who_crew\", \"what_crew\", \"when_crew\",\n",
        "    \"where_crew\", \"how_crew\", \"why_crew\",\n",
        "    \"quantum\", \"executor\", \"pipecat\"\n",
        "]\n",
        "\n",
        "# --- Connect to Docker \"Nervous System\" ---\n",
        "try:\n",
        "    docker_client = docker.from_env()\n",
        "    print(\"--- [DOCKER PROXY] Connected to Docker daemon. I am the guard. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- [DOCKER PROXY] CRITICAL: Failed to connect to Docker daemon: {e} ---\")\n",
        "    docker_client = None\n",
        "\n",
        "# --- Models for our secure endpoints ---\n",
        "class SpawnRequest(BaseModel):\n",
        "    agent_name: str\n",
        "    dockerfile_name: str\n",
        "    port: int\n",
        "\n",
        "class KillRequest(BaseModel):\n",
        "    container_id: str\n",
        "\n",
        "class RebuildRequest(BaseModel):\n",
        "    service_name: str # e.g., \"backend\" (the COO)\n",
        "\n",
        "@app.post(\"/secure-spawn-agent\")\n",
        "async def secure_spawn_agent(request: SpawnRequest):\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"Proxy cannot access Docker daemon.\"}\n",
        "\n",
        "    # --- WHITELIST CHECK ---\n",
        "    if request.agent_name not in ALLOWED_AGENT_NAMES or request.dockerfile_name not in ALLOWED_DOCKERFILES:\n",
        "        print(f\"--- [DOCKER PROXY] REJECTED: Spawn request for unknown agent: {request.agent_name} ---\")\n",
        "        return {\"status\": \"error\", \"message\": \"Request blocked by security proxy: Not a whitelisted agent.\"}\n",
        "\n",
        "    agent_name = request.agent_name\n",
        "    dockerfile = request.dockerfile_name\n",
        "    port = request.port\n",
        "\n",
        "    print(f\"--- [DOCKER PROXY] APPROVED: Spawning {agent_name}... ---\")\n",
        "    try:\n",
        "        image, _ = docker_client.images.build(path=\".\", dockerfile=dockerfile, tag=agent_name)\n",
        "        container = docker_client.containers.run(\n",
        "            image=agent_name,\n",
        "            detach=True,\n",
        "            ports={f'{port}/tcp': port},\n",
        "            network=\"frankenstein_net\",\n",
        "            name=f\"{agent_name}_ondemand_{port}\" # Give it a clear name\n",
        "        )\n",
        "        print(f\"--- [DOCKER PROXY] {agent_name} is LIVE. ID: {container.id} ---\")\n",
        "        return {\"status\": \"spawned\", \"agent_name\": agent_name, \"container_id\": container.id}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "@app.post(\"/secure-kill-agent\")\n",
        "async def secure_kill_agent(request: KillRequest):\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"Proxy cannot access Docker daemon.\"}\n",
        "\n",
        "    container_id = request.container_id\n",
        "    try:\n",
        "        container = docker_client.containers.get(container_id)\n",
        "\n",
        "        # --- PROTECTED CHECK ---\n",
        "        for protected in PROTECTED_CONTAINERS:\n",
        "            if protected in container.name:\n",
        "                print(f\"--- [DOCKER PROXY] REJECTED: Kill request for PROTECTED core service: {container.name} ---\")\n",
        "                return {\"status\": \"error\", \"message\": \"Request blocked by security proxy: Cannot kill core service.\"}\n",
        "\n",
        "        print(f\"--- [DOCKER PROXY] APPROVED: Killing container {container_id} ({container.name})... ---\")\n",
        "        container.stop()\n",
        "        container.remove()\n",
        "        return {\"status\": \"killed\", \"container_id\": container_id}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "# --- NEW Endpoint for Maintenance (Hulk Smash 13.0) ---\n",
        "@app.post(\"/secure-rebuild-service\")\n",
        "async def secure_rebuild_service(request: RebuildRequest):\n",
        "    \"\"\"\n",
        "    Safely rebuilds a \"core\" service container using docker-compose.\n",
        "    This is the \"auto-updater\" function for the CIO.\n",
        "    \"\"\"\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"Proxy cannot access Docker daemon.\"}\n",
        "\n",
        "    service_name = request.service_name\n",
        "\n",
        "    # --- WHITELIST CHECK ---\n",
        "    if service_name not in PROTECTED_CONTAINERS:\n",
        "        print(f\"--- [DOCKER PROXY] REJECTED: Rebuild request for unknown service: {service_name} ---\")\n",
        "        return {\"status\": \"error\", \"message\": \"Request blocked by security proxy: Not a whitelisted service.\"}\n",
        "\n",
        "    print(f\"--- [DOCKER PROXY] APPROVED: Rebuilding {service_name}... ---\")\n",
        "    try:\n",
        "        # This is the \"Hard Way\" command to safely rebuild & restart *one* service\n",
        "        # It will pull new images, build the container, and restart it.\n",
        "        # This requires 'docker-compose' to be installed in the proxy container.\n",
        "        import subprocess\n",
        "        process = subprocess.run(\n",
        "            [\"docker-compose\", \"up\", \"-d\", \"--no-deps\", \"--build\", service_name],\n",
        "            capture_output=True, text=True, cwd=\"/app\" # Assumes docker-compose.yml is in /app\n",
        "        )\n",
        "        if process.returncode == 0:\n",
        "            print(f\"--- [DOCKER PROXY] {service_name} has been rebuilt and restarted. ---\")\n",
        "            return {\"status\": \"rebuilt\", \"service_name\": service_name, \"logs\": process.stdout}\n",
        "        else:\n",
        "            print(f\"--- [DOCKER PROXY] REBUILD FAILED: {process.stderr} ---\")\n",
        "            return {\"status\": \"error\", \"message\": process.stderr}\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [Docker Security Proxy] Starting on http://0.0.0.0:6999 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=6999)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'docker_proxy.py' (Security Guard) CREATED.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mdfhv1UCayH",
        "outputId": "49bb9991-aaff-4118-a99f-960d0b93793e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'docker_proxy.py' (Security Guard) CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 25: The \"Security Guard\" Container\n",
        "# File: Dockerfile.docker_proxy\n",
        "#\n",
        "cat <<EOF > Dockerfile.docker_proxy\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The Proxy needs 'fastapi', 'docker', and 'httpx' (for our requirements file)\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster + \"Hulk Smash\" Tools ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "\n",
        "# --- Install \"Hulk Smash\" Maintenance Tools ---\n",
        "# We need 'docker-compose' for the auto-updater\n",
        "RUN apt-get update && apt-get install -y docker-compose-v2 && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "WORKDIR /app\n",
        "# We need ALL blueprints in here so docker-compose can build them\n",
        "COPY . .\n",
        "\n",
        "EXPOSE 6999\n",
        "CMD [\"uvicorn\", \"docker_proxy:app\", \"--host\", \"0.0.0.0\", \"--port\", \"6999\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.docker_proxy' (Security Guard) CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kxiAAQ7Ch0K",
        "outputId": "a21df3f1-d23a-4d7b-8bac-388feb9e4858"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.docker_proxy' (Security Guard) CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 16 (v3): The \"Neutered\" CTO (Security-Aware)\n",
        "# File: cto_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > cto_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "# --- NO MORE DOCKER IMPORT ---\n",
        "# We have been neutered. We are no longer the \"god\" process.\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CTO's NEW \"Nervous System\" ---\n",
        "# We no longer talk to Docker. We talk to the \"Security Guard\".\n",
        "PROXY_SPAWN_URL = \"http://docker_proxy:6999/secure-spawn-agent\"\n",
        "PROXY_KILL_URL = \"http://docker_proxy:6999/secure-kill-agent\"\n",
        "PROXY_REBUILD_URL = \"http://docker_proxy:6999/secure-rebuild-service\"\n",
        "\n",
        "# We still talk to our \"hands\"\n",
        "EXECUTOR_URL = \"http://executor:9090/run-code\"\n",
        "\n",
        "# --- Models for our endpoints ---\n",
        "class CodeRequest(BaseModel):\n",
        "    code: str\n",
        "\n",
        "class SpawnRequest(BaseModel):\n",
        "    agent_name: str\n",
        "    dockerfile_name: str\n",
        "    port: int\n",
        "\n",
        "class KillRequest(BaseModel):\n",
        "    container_id: str\n",
        "\n",
        "class RebuildRequest(BaseModel):\n",
        "    service_name: str\n",
        "\n",
        "# --- Endpoint 1: Run Simulations (Original Job) ---\n",
        "@app.post(\"/run-simulation\")\n",
        "async def run_simulation(request: CodeRequest):\n",
        "    print(f\"--- [CTO] Received simulation request. Asking Executor... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            exec_response = await client.post(EXECUTOR_URL, json=request.dict(), timeout=300)\n",
        "            return exec_response.json()\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"Simulation FAILED. Could not contact Executor: {e}\"}\n",
        "\n",
        "# --- Endpoint 2: ASK to Spawn Agent ---\n",
        "@app.post(\"/spawn-agent\")\n",
        "async def spawn_agent(request: SpawnRequest):\n",
        "    print(f\"--- [CTO] Asking Proxy to spawn {request.agent_name}... ---\")\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        proxy_res = await client.post(PROXY_SPAWN_URL, json=request.dict())\n",
        "    return proxy_res.json()\n",
        "\n",
        "# --- Endpoint 3: ASK to Kill Agent ---\n",
        "@app.post(\"/kill-agent\")\n",
        "async def kill_agent(request: KillRequest):\n",
        "    print(f\"--- [CTO] Asking Proxy to kill {request.container_id}... ---\")\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        proxy_res = await client.post(PROXY_KILL_URL, json=request.dict())\n",
        "    return proxy_res.json()\n",
        "\n",
        "# --- Endpoint 4: ASK to Rebuild Service (Hulk Smash 13.0) ---\n",
        "@app.post(\"/rebuild-service\")\n",
        "async def rebuild_service(request: RebuildRequest):\n",
        "    print(f\"--- [CTO] Asking Proxy to rebuild {request.service_name}... ---\")\n",
        "    async with httpx.AsyncClient(timeout=600.0) as client: # 10 min timeout for build\n",
        "        proxy_res = await client.post(PROXY_REBUILD_URL, json=request.dict())\n",
        "    return proxy_res.json()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CTO (Neutered) Server v3] Starting on http://0.0.0.0:5002 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5002)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cto_server.py' (v3 'Neutered') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyIRajgRCxVW",
        "outputId": "c2647397-c831-4d6e-b929-14d8c44e2dc5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cto_server.py' (v3 'Neutered') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 19 (v2): The \"CIO\" (Auto-Updater) Agent Code\n",
        "# File: cio_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > cio_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import subprocess\n",
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CIO knows how to talk to the \"CTO\" (who will talk to the \"Proxy\")\n",
        "CTO_REBUILD_URL = \"http://cto:5002/rebuild-service\"\n",
        "\n",
        "@app.post(\"/check-for-updates\")\n",
        "async def check_for_updates():\n",
        "    print(\"--- [CIO] Checking for updates... Running 'git pull'... ---\")\n",
        "    try:\n",
        "        # --- 1. Run 'git pull' to get new blueprints ---\n",
        "        # This requires 'git' to be in the container\n",
        "        process = subprocess.run(\n",
        "            [\"git\", \"pull\"],\n",
        "            capture_output=True, text=True, cwd=\"/app\"\n",
        "        )\n",
        "\n",
        "        git_logs = process.stdout\n",
        "        print(f\"--- [CIO] Git pull complete: {git_logs} ---\")\n",
        "\n",
        "        if \"Already up to date.\" in git_logs:\n",
        "            return {\"status\": \"no_updates\", \"logs\": git_logs}\n",
        "\n",
        "        # --- 2. Find which blueprints were changed ---\n",
        "        # (This is a simple logic; a real one would be more complex)\n",
        "        updated_services = []\n",
        "        if \"ceo_server.py\" in git_logs:\n",
        "            updated_services.append(\"ceo\")\n",
        "        if \"backend_server.py\" in git_logs:\n",
        "            updated_services.append(\"backend\")\n",
        "        if \"pipecat_server.py\" in git_logs:\n",
        "            updated_services.append(\"pipecat\")\n",
        "\n",
        "        if not updated_services:\n",
        "            return {\"status\": \"updates_pulled\", \"logs\": git_logs, \"message\": \"No core services changed.\"}\n",
        "\n",
        "        # --- 3. Tell the CTO to rebuild the changed services ---\n",
        "        print(f\"--- [CIO] Found updates for: {updated_services}. Asking CTO to rebuild... ---\")\n",
        "        rebuild_reports = {}\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            for service in updated_services:\n",
        "                rebuild_res = await client.post(CTO_REBUILD_URL, json={\"service_name\": service})\n",
        "                rebuild_reports[service] = rebuild_res.json()\n",
        "\n",
        "        return {\"status\": \"updates_applied\", \"rebuild_reports\": rebuild_reports}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CIO] Update check FAILED: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CIO (Auto-Updater) Server v2] Starting on http://0.0.0.0:5005 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5005)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cio_server.py' (v2 'Auto-Updater') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_M4wF2kC9Dt",
        "outputId": "188f3963-13be-48d1-cb26-cbc70414d50c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cio_server.py' (v2 'Auto-Updater') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v5): The \"CEO\" (Maintenance Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import asyncio\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "# The CEO now talks to the \"Neutered\" CTO\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "# The \"CIO\" (Auto-Updater) is now spawned on-demand\n",
        "CIO_URL = \"http://cio:5005/check-for-updates\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Directory\n",
        "AGENT_DIRECTORY = {\n",
        "    \"cmo\": {\"port\": 5003, \"dockerfile\": \"Dockerfile.cmo\", \"endpoint\": \"/run-marketing-plan\"},\n",
        "    \"chro\": {\"port\": 5004, \"dockerfile\": \"Dockerfile.chro\", \"endpoint\": \"/review-performance\"},\n",
        "    \"cio\": {\"port\": 5005, \"dockerfile\": \"Dockerfile.cio\", \"endpoint\": \"/check-for-updates\"},\n",
        "    \"csco\": {\"port\": 5006, \"dockerfile\": \"Dockerfile.csco\", \"endpoint\": \"/run-supply-chain-plan\"},\n",
        "    \"cco\": {\"port\": 5007, \"dockerfile\": \"Dockerfile.cco\", \"endpoint\": \"/run-comms-plan\"},\n",
        "    \"cso\": {\"port\": 5008, \"dockerfile\": \"Dockerfile.cso\", \"endpoint\": \"/run-sustainability-plan\"},\n",
        "    \"cdo\": {\"port\": 5009, \"dockerfile\": \"Dockerfile.cdo\", \"endpoint\": \"/run-diversity-plan\"},\n",
        "}\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    required_officers: List[str] = []\n",
        "\n",
        "# --- Helper Functions (The \"CEO's EA\") ---\n",
        "async def spawn_agent(client, agent_name):\n",
        "    if agent_name not in AGENT_DIRECTORY: return None, None\n",
        "    config = AGENT_DIRECTORY[agent_name]\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name, \"dockerfile_name\": config[\"dockerfile\"], \"port\": config[\"port\"]\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        container_id = spawn_res.json().get(\"container_id\")\n",
        "        return f\"http://{agent_name}:{config['port']}{config['endpoint']}\", container_id\n",
        "    return None, None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "# --- The \"C-Suite\" Mission Endpoint ---\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    hired_agents: Dict[str, Any] = {} # {container_id: {\"name\": agent_name, \"report\": ...}}\n",
        "    mission_results = {}\n",
        "    chro_container_id = None\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            mission_results[\"clo_approval\"] = clo_response.json()\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff ---\n",
        "            for agent_name in request.required_officers:\n",
        "                if agent_name in AGENT_DIRECTORY and agent_name != \"cio\": # CIO is special\n",
        "                    url, container_id = await spawn_agent(client, agent_name)\n",
        "                    if not container_id:\n",
        "                        return {\"result\": f\"Mission FAILED. Could not hire {agent_name}.\"}\n",
        "                    hired_agents[container_id] = {\"name\": agent_name, \"report\": {}}\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} is hired. Delegating task... ---\")\n",
        "                    async with httpx.AsyncClient(timeout=300.0) as agent_client:\n",
        "                        agent_res = await agent_client.post(url)\n",
        "                    agent_report = agent_res.json()\n",
        "                    hired_agents[container_id][\"report\"] = agent_report\n",
        "                    mission_results[f\"{agent_name}_report\"] = agent_report\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client:\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "            if coo_response.status_code != 200: return {\"result\": \"Mission FAILED. COO reported an error.\"}\n",
        "            mission_results[\"coo_report\"] = coo_response.json().get(\"result\")\n",
        "\n",
        "            # --- 4. \"PERFORMANCE REVIEW\" LOOP ---\n",
        "            if hired_agents:\n",
        "                print(\"--- [CEO] Hiring CHRO for performance reviews... ---\")\n",
        "                chro_url, chro_container_id = await spawn_agent(client, \"chro\")\n",
        "                if chro_container_id:\n",
        "                    for agent_data in hired_agents.values():\n",
        "                        await client.post(chro_url, json={\n",
        "                            \"agent_name\": agent_data['name'], \"report\": agent_data['report']\n",
        "                        })\n",
        "                    print(\"--- [CEO] Performance reviews complete. ---\")\n",
        "\n",
        "            mission_results[\"status\"] = \"Mission Accomplished\"\n",
        "            return mission_results\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 5. FIRE \"Part-Time\" Staff ---\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            for container_id in hired_agents.keys():\n",
        "                await kill_agent(client, container_id)\n",
        "            if chro_container_id:\n",
        "                await kill_agent(client, chro_container_id)\n",
        "\n",
        "# --- NEW: \"Maintenance\" Endpoint (Hulk Smash 13.0) ---\n",
        "@app.post(\"/run-maintenance\")\n",
        "async def run_maintenance():\n",
        "    \"\"\"\n",
        "    The CEO will \"hire\" the CIO to check for updates\n",
        "    and then \"fire\" it when it's done.\n",
        "    \"\"\"\n",
        "    print(\"--- [CEO] Maintenance mission received. Hiring CIO... ---\")\n",
        "    cio_container_id = None\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            # 1. Hire CIO\n",
        "            cio_url, cio_container_id = await spawn_agent(client, \"cio\")\n",
        "            if not cio_container_id:\n",
        "                return {\"result\": \"Maintenance FAILED. Could not hire CIO.\"}\n",
        "\n",
        "            # 2. Task CIO (with a long timeout for 'git pull')\n",
        "            print(\"--- [CEO] CIO is hired. Delegating 'check-for-updates'... ---\")\n",
        "            async with httpx.AsyncClient(timeout=600.0) as cio_client:\n",
        "                cio_res = await cio_client.post(cio_url)\n",
        "\n",
        "            report = cio_res.json()\n",
        "            print(f\"--- [CEO] CIO has reported back: {report} ---\")\n",
        "            return {\"status\": \"Maintenance complete.\", \"report\": report}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"Maintenance FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # 3. Fire CIO\n",
        "        if cio_container_id:\n",
        "            async with httpx.AsyncClient() as client:\n",
        "                await kill_agent(client, cio_container_id)\n",
        "            print(\"--- [CEO] CIO 'fired'. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Maintenance Manager) Server v5] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v5 'Maintenance Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D66WCwoIDQZt",
        "outputId": "798733cc-6bda-43fa-b730-eef8d52729b4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v5 'Maintenance Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v8 - \"Frankenstein 5.0\"): Secure & Evolving Swarm\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "volumes:\n",
        "  corporate_memory_data:\n",
        "\n",
        "services:\n",
        "  # --- 1. \"STAKEHOLDER\" (Avatar) ---\n",
        "  pipecat:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.pipecat\n",
        "    ports:\n",
        "      - \"7456:7456\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    env_file:\n",
        "      - .env\n",
        "    depends_on:\n",
        "      - ceo\n",
        "\n",
        "  # --- 2. \"SECURITY\" (The \"Padded Cell\") ---\n",
        "  docker_proxy:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.docker_proxy\n",
        "    ports:\n",
        "      - \"6999:6999\" # The \"Security Guard\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # --- THIS IS THE \"GOD MODE\" ---\n",
        "    # This is the *only* service that gets the Docker socket\n",
        "    volumes:\n",
        "      - /var/run/docker.sock:/var/run/docker.sock\n",
        "      # It also needs access to the blueprints to run 'docker-compose'\n",
        "      - .:/app\n",
        "    depends_on:\n",
        "      - librarian # Ensure memory is up first\n",
        "      - executor # Ensure hands are up first\n",
        "\n",
        "  # --- 3. \"FULL-TIME\" C-SUITE (The \"Core\") ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cto       # \"Neutered\" CTO\n",
        "      - docker_proxy # Must wait for the \"Guard\"\n",
        "\n",
        "  clo: # Legal (Guardrail)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto: # The \"Neutered\" Agent Spawner\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor\n",
        "      - docker_proxy\n",
        "    # --- NO MORE DOCKER SOCKET ---\n",
        "    # The \"god mode\" has been removed.\n",
        "\n",
        "  # --- 4. \"CORPORATE MEMORY\" ---\n",
        "  librarian:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.librarian\n",
        "    ports:\n",
        "      - \"6000:6000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    volumes:\n",
        "      - corporate_memory_data:/chroma-data\n",
        "\n",
        "  # --- 5. \"FULL-TIME\" OPERATIONS (COO & Laborers) ---\n",
        "  backend: # \"COO\"\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 'SECURE v8' 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpBWsSjPD58u",
        "outputId": "a42120b3-4e01-4c6b-a44f-357370cd08ec"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 'SECURE v8' 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 3483 Nov 24 13:33 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 26: Create the \"Organized Castle\"\n",
        "#\n",
        "mkdir -p dockerfiles\n",
        "mkdir -p services\n",
        "\n",
        "echo \"✅ 'dockerfiles' and 'services' folders blueprinted.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwXBm4ayEdH8",
        "outputId": "4d0e437a-5841-4b14-e5f6-0c57eb8dde60"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 'dockerfiles' and 'services' folders blueprinted.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6OlRrZFGRcl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}