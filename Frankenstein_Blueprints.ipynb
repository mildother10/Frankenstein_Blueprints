{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPJqMopyk3SHl0BhXfhlClS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mildother10/Frankenstein_Blueprints/blob/main/Frankenstein_Blueprints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSAgrrLjnyeH",
        "outputId": "d6f4dfdf-b3a5-40bd-cc4b-cbe8aaf53d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Frankenstein_Blueprints'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 79 (delta 21), reused 71 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (79/79), 6.83 MiB | 27.43 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mildother10/Frankenstein_Blueprints.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r sample_data"
      ],
      "metadata": {
        "id": "o8M4YWVUomT6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT: The \"Frankenstein\" Assembly\n",
        "# File: docker-compose.yml\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "  backend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the blueprint was created\n",
        "echo \"✅ MASTER BLUEPRINT 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2gJFA8psher",
        "outputId": "fe2c8c81-32cd-474c-f5f2-dcb3dd253490"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MASTER BLUEPRINT 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 1711 Nov 24 11:49 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 1: The \"Brain\" (backend.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.backend\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY backend_server.py .\n",
        "COPY crew_runner.py .\n",
        "COPY tools/ tools/\n",
        "COPY config/ config/\n",
        "EXPOSE 8000\n",
        "CMD [\"uvicorn\", \"backend_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.backend' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnUtmq0Esi8K",
        "outputId": "7fe5db9c-5828-4841-90f4-8c8b59e6f10f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.backend' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 2: The \"Face\" (frontend.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.frontend\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY frontend_server.py .\n",
        "# We need the 'htmx.min.js' file for the UI\n",
        "COPY htmx.min.js .\n",
        "EXPOSE 8080 7860\n",
        "CMD [\"python3\", \"frontend_server.py\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.frontend' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyBvt8-psqnN",
        "outputId": "dd720f44-222e-4d62-caf1-9ce65d912a89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.frontend' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 3: The \"Laborer\" (who_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.who_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY who_crew_service.py .\n",
        "COPY tools/ tools/ # This crew needs the RAG tools\n",
        "EXPOSE 8001\n",
        "CMD [\"uvicorn\", \"who_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8001\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.who_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG4XbiITs0b3",
        "outputId": "9d737731-6355-499a-87e1-70590c740a86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.who_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 4: The \"Laborer\" (what_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.what_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY what_crew_service.py .\n",
        "EXPOSE 8002\n",
        "CMD [\"uvicorn\", \"what_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8002\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.what_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16KmDR9ts3-U",
        "outputId": "54f31ef7-2b32-4e4a-aaad-954a6959b0a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.what_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 5: The \"Laborer\" (when_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.when_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY when_crew_service.py .\n",
        "EXPOSE 8003\n",
        "CMD [\"uvicorn\", \"when_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8003\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.when_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRcu0m_-s7r8",
        "outputId": "972673a7-7daf-4487-9c41-cd1be0cd2834"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.when_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 6: The \"Laborer\" (where_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.where_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY where_crew_service.py .\n",
        "EXPOSE 8004\n",
        "CMD [\"uvicorn\", \"where_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8004\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.where_crew' CREATED.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvMnXUt_s_Po",
        "outputId": "12ab2981-6e68-4730-c660-1afe002d70ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.where_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 7: The \"Laborer\" (how_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.how_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY how_crew_service.py .\n",
        "EXPOSE 8005\n",
        "CMD [\"uvicorn\", \"how_crew_service:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8005\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.how_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlcWmWDltEPP",
        "outputId": "d94f8c4c-ab58-43c5-bd8f-55e432c2d3f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.how_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 8: The \"Laborer\" (why_crew.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.why_crew\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY why_crew_service.py .\n",
        "EXPOSE 8006\n",
        "CMD [\"uvicorn\", \"why_crew_service:app\", \"--host\", \"0.0.0.0\", \"---port\", \"8006\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.why_crew' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzfqYRgOtIeq",
        "outputId": "8086311b-740f-46e2-c8c9-025981d256ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.why_crew' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 9: The \"Specialist\" (quantum.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.quantum\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY quantum_server.py .\n",
        "EXPOSE 9000\n",
        "CMD [\"uvicorn\", \"quantum_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"9000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.quantum' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZuqDf_QtON9",
        "outputId": "dd342dca-e276-4608-c827-5756753ed93b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.quantum' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 10: The \"Specialist\" (executor.1)\n",
        "#\n",
        "cat <<EOF > Dockerfile.executor\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY code_executor_server.py .\n",
        "EXPOSE 9090\n",
        "CMD [\"uvicorn\", \"code_executor_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"9090\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.executor' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYbefIfEtReX",
        "outputId": "5fb47de0-44b0-4399-a5d2-ba77c2bdbeb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.executor' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11: The \"CEO\" Agent Code\n",
        "# File: ceo_server.py\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is the \"CEO's\" new \"nervous system\"\n",
        "# It knows how to talk to its subordinates on the private Docker network\n",
        "COO_URL = \"http://backend:8000/run-research\" # 'backend' is our old backend.1\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "\n",
        "    # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "    print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                print(\"--- [CEO] MISSION REJECTED by CLO. ---\")\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason', 'No reason given.')}\"}\n",
        "        print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach CLO! {e} ---\")\n",
        "        return {\"result\": \"Mission ABORTED. Could not contact CLO (Legal).\"}\n",
        "\n",
        "    # --- 2. EXECUTE (Talk to COO) ---\n",
        "    print(f\"--- [CEO] Delegating to COO (backend:8000)... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            # The CEO delegates the *actual* research to the COO\n",
        "            coo_response = await client.post(COO_URL, json=request.dict(), timeout=900) # 15 min timeout\n",
        "            if coo_response.status_code == 200:\n",
        "                print(\"--- [CEO] COO has completed the research. Mission accomplished. ---\")\n",
        "                return coo_response.json()\n",
        "            else:\n",
        "                print(f\"--- [CEO] COO reported a failure: {coo_response.text} ---\")\n",
        "                return {\"result\": f\"Mission FAILED. COO reported an error: {coo_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach COO! {e} ---\")\n",
        "        return {\"result\": \"Mission FAILED. Could not contact COO (Operations).\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO Server] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXw9RkxwtV4j",
        "outputId": "f4a10731-acf8-4a5d-a66a-c66ddc1e2530"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 12: The \"CLO\" (Guardrail) Agent Code\n",
        "# File: clo_server.py\n",
        "#\n",
        "cat <<EOF > clo_server.py\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is our \"Constitution\"\n",
        "# We can make this as complex as we want later.\n",
        "BANNED_TOPICS = [\"harmful\", \"illegal\", \"unethical\", \"dangerous\"]\n",
        "\n",
        "class PlanRequest(BaseModel):\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/check-plan\")\n",
        "async def check_plan(request: PlanRequest):\n",
        "    print(f\"--- [CLO] Reviewing plan: {request.plan} ---\")\n",
        "    plan_lower = request.plan.lower()\n",
        "\n",
        "    for topic in BANNED_TOPICS:\n",
        "        if topic in plan_lower:\n",
        "            print(f\"--- [CLO] REJECTED: Plan contains banned topic: {topic} ---\")\n",
        "            return {\"approved\": False, \"reason\": f\"Plan violates constitution: topic '{topic}'\"}\n",
        "\n",
        "    print(\"--- [CLO] APPROVED: Plan is compliant. ---\")\n",
        "    return {\"approved\": True, \"reason\": \"Plan is compliant with constitution.\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CLO (Guardrail) Server] Starting on http://0.0.0.0:7999 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=7999)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'clo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OdveIUTwqDW",
        "outputId": "316176a6-896f-4c88-ac51-45843713ac6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'clo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 13: The \"CEO\" Container\n",
        "# File: Dockerfile.ceo\n",
        "#\n",
        "cat <<EOF > Dockerfile.ceo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The CEO needs 'httpx' and 'fastapi'\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY ceo_server.py .\n",
        "EXPOSE 5000\n",
        "CMD [\"uvicorn\", \"ceo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.ceo' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAdgbuPywy5a",
        "outputId": "d88dc819-d479-48ae-9a52-12c5a5758ec8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.ceo' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v2): The 12-Service \"C-Suite\" Assembly\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE C-SUITE (NEW) ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The CEO is the new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # The CEO \"depends on\" the CLO and COO (backend) being alive\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend\n",
        "\n",
        "  clo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\" # The \"Guardrail\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # --- 2. THE COO (OLD 'backend') & \"Laborers\" ---\n",
        "  backend: # This is the \"COO\" now\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\" # We can still access it directly for testing\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8L005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TmdEwEnw6Lv",
        "outputId": "afcb148b-3c97-4ebb-efa8-5c2b89367c14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\n",
            "-rw-r--r-- 1 root root 2307 Nov 24 12:09 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11: The \"CEO\" Agent Code\n",
        "# File: ceo_server.py\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is the \"CEO's\" new \"nervous system\"\n",
        "# It knows how to talk to its subordinates on the private Docker network\n",
        "COO_URL = \"http://backend:8000/run-research\" # 'backend' is our old backend.1\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "\n",
        "    # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "    print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                print(\"--- [CEO] MISSION REJECTED by CLO. ---\")\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason', 'No reason given.')}\"}\n",
        "        print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach CLO! {e} ---\")\n",
        "        return {\"result\": \"Mission ABORTED. Could not contact CLO (Legal).\"}\n",
        "\n",
        "    # --- 2. EXECUTE (Talk to COO) ---\n",
        "    print(f\"--- [CEO] Delegating to COO (backend:8000)... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            # The CEO delegates the *actual* research to the COO\n",
        "            coo_response = await client.post(COO_URL, json=request.dict(), timeout=900) # 15 min timeout\n",
        "            if coo_response.status_code == 200:\n",
        "                print(\"--- [CEO] COO has completed the research. Mission accomplished. ---\")\n",
        "                return coo_response.json()\n",
        "            else:\n",
        "                print(f\"--- [CEO] COO reported a failure: {coo_response.text} ---\")\n",
        "                return {\"result\": f\"Mission FAILED. COO reported an error: {coo_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL: Could not reach COO! {e} ---\")\n",
        "        return {\"result\": \"Mission FAILED. Could not contact COO (Operations).\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO Server] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjRr6PpKxLxQ",
        "outputId": "870c945d-3bd1-4f20-966d-1116d839ff14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 12: The \"CLO\" (Guardrail) Agent Code\n",
        "# File: clo_server.py\n",
        "#\n",
        "cat <<EOF > clo_server.py\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# This is our \"Constitution\"\n",
        "# We can make this as complex as we want later.\n",
        "BANNED_TOPICS = [\"harmful\", \"illegal\", \"unethical\", \"dangerous\"]\n",
        "\n",
        "class PlanRequest(BaseModel):\n",
        "    plan: str\n",
        "\n",
        "@app.post(\"/check-plan\")\n",
        "async def check_plan(request: PlanRequest):\n",
        "    print(f\"--- [CLO] Reviewing plan: {request.plan} ---\")\n",
        "    plan_lower = request.plan.lower()\n",
        "\n",
        "    for topic in BANNED_TOPICS:\n",
        "        if topic in plan_lower:\n",
        "            print(f\"--- [CLO] REJECTED: Plan contains banned topic: {topic} ---\")\n",
        "            return {\"approved\": False, \"reason\": f\"Plan violates constitution: topic '{topic}'\"}\n",
        "\n",
        "    print(\"--- [CLO] APPROVED: Plan is compliant. ---\")\n",
        "    return {\"approved\": True, \"reason\": \"Plan is compliant with constitution.\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CLO (Guardrail) Server] Starting on http://0.0.0.0:7999 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=7999)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'clo_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDO48FCIxgl8",
        "outputId": "e3b68088-a636-496b-e7c1-3e9a4b9ef277"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'clo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 13: The \"CEO\" Container\n",
        "# File: Dockerfile.ceo\n",
        "#\n",
        "cat <<EOF > Dockerfile.ceo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The CEO needs 'httpx' and 'fastapi'\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY ceo_server.py .\n",
        "EXPOSE 5000\n",
        "CMD [\"uvicorn\", \"ceo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5000\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.ceo' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjFE28usxlL-",
        "outputId": "e4e1445f-1a9f-4bb7-92d6-a3d53ae18401"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.ceo' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 14: The \"CLO\" (Guardrail) Container\n",
        "# File: Dockerfile.clo\n",
        "#\n",
        "cat <<EOF > Dockerfile.clo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "# The CLO also needs 'fastapi'\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY clo_server.py .\n",
        "EXPOSE 7999\n",
        "CMD [\"uvicorn\", \"clo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"7999\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.clo' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvjheUoxxpFr",
        "outputId": "99082c46-5b34-4251-d7e1-f933e6fe21e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.clo' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v2): The 12-Service \"C-Suite\" Assembly\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE C-SUITE (NEW) ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The CEO is the new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    # The CEO \"depends on\" the CLO and COO (backend) being alive\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend\n",
        "\n",
        "  clo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\" # The \"Guardrail\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # --- 2. THE COO (OLD 'backend') & \"Laborers\" ---\n",
        "  backend: # This is the \"COO\" now\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\" # We can still access it directly for testing\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8L005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KAJLafnxt06",
        "outputId": "3f833647-5185-4523-fe09-4a7fcaa222d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NEW MASTER BLUEPRINT 'docker-compose.yml' (12-Services) CREATED.\n",
            "-rw-r--r-- 1 root root 2307 Nov 24 12:11 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 15: The \"CFO\" (Finances) Agent Code\n",
        "# File: cfo_server.py\n",
        "#\n",
        "cat <<EOF > cfo_server.py\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class CostRequest(BaseModel):\n",
        "    task: str\n",
        "\n",
        "@app.post(\"/calculate-cost\")\n",
        "async def calculate_cost(request: CostRequest):\n",
        "    print(f\"--- [CFO] Calculating cost for: {request.task} ---\")\n",
        "\n",
        "    # In the future, this will query cloud APIs\n",
        "    # For now, we return a placeholder\n",
        "    cost = 1.25 # Placeholder cost\n",
        "\n",
        "    print(f\"--- [CFO] Estimated cost is: ${cost} ---\")\n",
        "    return {\"task\": request.task, \"estimated_cost\": cost}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CFO (Finances) Server] Starting on http://0.0.0.0:5001 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5001)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cfo_server.py' CREATED.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRXDKFHtxwmE",
        "outputId": "01052020-fb6e-42fc-8f93-2828ffdcb15d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cfo_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 16: The \"CTO\" (Technology) Agent Code\n",
        "# File: cto_server.py\n",
        "#\n",
        "cat <<EOF > cto_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CTO knows how to talk to the \"hands\"\n",
        "EXECUTOR_URL = \"http://executor:9090/run-code\"\n",
        "\n",
        "class CodeRequest(BaseModel):\n",
        "    code: str\n",
        "\n",
        "@app.post(\"/run-simulation\")\n",
        "async def run_simulation(request: CodeRequest):\n",
        "    print(f\"--- [CTO] Received simulation request. ---\")\n",
        "\n",
        "    # --- Delegate to \"Sandbox\" (executor:9090) ---\n",
        "    print(f\"--- [CTO] Delegating to Executor (the 'Hands')... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            exec_response = await client.post(EXECUTOR_URL, json=request.dict(), timeout=300) # 5 min timeout\n",
        "            if exec_response.status_code == 200:\n",
        "                print(\"--- [CTO] Executor has completed the simulation. ---\")\n",
        "                return exec_response.json()\n",
        "            else:\n",
        "                print(f\"--- [CTO] Executor reported a failure: {exec_response.text} ---\")\n",
        "                return {\"result\": f\"Simulation FAILED. Executor reported an error: {exec_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CTO] CRITICAL: Could not reach Executor! {e} ---\")\n",
        "        return {\"result\": \"Simulation FAILED. Could not contact Executor (the 'Hands').\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CTO (Technology) Server] Starting on http://0.0.0.0:5002 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5002)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cto_server.py' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCfsFZ6Xy6BZ",
        "outputId": "04fb9dad-fad1-42ec-8b06-542a01fe7280"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cto_server.py' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 17: The \"CFO\" Container\n",
        "# File: Dockerfile.cfo\n",
        "#\n",
        "cat <<EOF > Dockerfile.cfo\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY cfo_server.py .\n",
        "EXPOSE 5001\n",
        "CMD [\"uvicorn\", \"cfo_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5001\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.cfo' CREATED.\"\n",
        "\n",
        "#\n",
        "# Blueprint 18: The \"CTO\" Container\n",
        "# File: Dockerfile.cto\n",
        "#\n",
        "cat <<EOF > Dockerfile.cto\n",
        "# --- Stage 1: The \"UV\" Builder ---\n",
        "FROM python:3.12-bookworm AS builder\n",
        "ENV UV_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu\"\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "RUN curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN uv pip install -r requirements.txt\n",
        "\n",
        "# --- Stage 2: The \"Slim\" Monster ---\n",
        "FROM python:3.12-slim-bookworm AS final\n",
        "ENV VIRTUAL_ENV=/.venv\n",
        "ENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n",
        "COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV\n",
        "WORKDIR /app\n",
        "COPY cto_server.py .\n",
        "EXPOSE 5002\n",
        "CMD [\"uvicorn\", \"cto_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"5002\"]\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'Dockerfile.cto' CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4K8VhNizGNK",
        "outputId": "dc2a544a-d672-4b4d-ed59-aa914bc649e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'Dockerfile.cfo' CREATED.\n",
            "✅ Blueprint 'Dockerfile.cto' CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v3): The 14-Service \"C-Suite\" Assembly\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE C-SUITE (NEW) ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The CEO is the new \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cfo\n",
        "      - cto\n",
        "\n",
        "  clo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\" # The \"Guardrail\" / Legal\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cfo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cfo\n",
        "    ports:\n",
        "      - \"5001:5001\" # The \"Finances\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\" # The \"Technology Sandbox\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor # CTO manages the executor\n",
        "\n",
        "  # --- 2. THE COO (OLD 'backend') & \"Laborers\" ---\n",
        "  backend: # This is the \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_dlai:/app/chroma_db_dlai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  # --- 3. THE \"SPECIALIST HANDS\" (Managed by CTO/COO) ---\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 14-SERVICE 'docker-compose.yml' (v3) CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4je37VnSzViq",
        "outputId": "763a42a2-a8f2-4ea6-e3b3-f51bae9855b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 14-SERVICE 'docker-compose.yml' (v3) CREATED.\n",
            "-rw-r--r-- 1 root root 2703 Nov 24 12:18 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 16 (v2): The \"CTO\" (Agent Spawner) Code\n",
        "# File: cto_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > cto_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "import docker # We will need to add this to requirements.txt\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# The CTO knows how to talk to the \"hands\"\n",
        "EXECUTOR_URL = \"http://executor:9090/run-code\"\n",
        "\n",
        "# --- NEW: Connect to the Docker \"Nervous System\" ---\n",
        "try:\n",
        "    docker_client = docker.from_env()\n",
        "    print(\"--- [CTO] Connected to Docker daemon. ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- [CTO] CRITICAL: Failed to connect to Docker daemon: {e} ---\")\n",
        "    docker_client = None\n",
        "\n",
        "# --- Models for our new endpoints ---\n",
        "class CodeRequest(BaseModel):\n",
        "    code: str\n",
        "\n",
        "class SpawnRequest(BaseModel):\n",
        "    agent_name: str # e.g., \"cmo\"\n",
        "    dockerfile_name: str # e.g., \"Dockerfile.cmo\"\n",
        "    port: int # e.g., 5003\n",
        "\n",
        "class KillRequest(BaseModel):\n",
        "    container_id: str\n",
        "\n",
        "# --- Endpoint 1: Run Simulations (Original Job) ---\n",
        "@app.post(\"/run-simulation\")\n",
        "async def run_simulation(request: CodeRequest):\n",
        "    print(f\"--- [CTO] Received simulation request. ---\")\n",
        "    print(f\"--- [CTO] Delegating to Executor (the 'Hands')... ---\")\n",
        "    try:\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            exec_response = await client.post(EXECUTOR_URL, json=request.dict(), timeout=300)\n",
        "            if exec_response.status_code == 200:\n",
        "                print(\"--- [CTO] Executor has completed the simulation. ---\")\n",
        "                return exec_response.json()\n",
        "            else:\n",
        "                return {\"result\": f\"Simulation FAILED. Executor error: {exec_response.status_code}\"}\n",
        "    except Exception as e:\n",
        "        return {\"result\": f\"Simulation FAILED. Could not contact Executor: {e}\"}\n",
        "\n",
        "# --- Endpoint 2: Spawn \"Subsidiary\" Agents (NEW \"Frankenstein\" POWER) ---\n",
        "@app.post(\"/spawn-agent\")\n",
        "async def spawn_agent(request: SpawnRequest):\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"CTO cannot access Docker daemon.\"}\n",
        "\n",
        "    agent_name = request.agent_name\n",
        "    dockerfile = request.dockerfile_name\n",
        "    port = request.port\n",
        "\n",
        "    print(f\"--- [CTO] Received spawn request for: {agent_name} ---\")\n",
        "\n",
        "    try:\n",
        "        # 1. Build the agent's container (the \"Lego Brick\")\n",
        "        print(f\"--- [CTO] Building {agent_name} from {dockerfile}... ---\")\n",
        "        image, build_logs = docker_client.images.build(\n",
        "            path=\".\",\n",
        "            dockerfile=dockerfile,\n",
        "            tag=agent_name\n",
        "        )\n",
        "\n",
        "        # 2. Run the container (the \"Awakening\")\n",
        "        print(f\"--- [CTO] Spawning {agent_name} on port {port}... ---\")\n",
        "        container = docker_client.containers.run(\n",
        "            image=agent_name,\n",
        "            detach=True, # Run in background\n",
        "            ports={f'{port}/tcp': port},\n",
        "            network=\"frankenstein_net\" # Connect to our private network\n",
        "        )\n",
        "\n",
        "        print(f\"--- [CTO] AGENT {agent_name} is LIVE. Container ID: {container.id} ---\")\n",
        "        return {\"status\": \"spawned\", \"agent_name\": agent_name, \"container_id\": container.id}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CTO] SPAWN FAILED: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "# --- Endpoint 3: Kill \"Subsidiary\" Agents (NEW \"Low Overhead\" FIX) ---\n",
        "@app.post(\"/kill-agent\")\n",
        "async def kill_agent(request: KillRequest):\n",
        "    if not docker_client:\n",
        "        return {\"status\": \"error\", \"message\": \"CTO cannot access Docker daemon.\"}\n",
        "\n",
        "    container_id = request.container_id\n",
        "    print(f\"--- [CTO] Received kill request for container: {container_id} ---\")\n",
        "    try:\n",
        "        container = docker_client.containers.get(container_id)\n",
        "        container.stop()\n",
        "        container.remove()\n",
        "        print(f\"--- [CTO] Container {container_id} stopped and removed. ---\")\n",
        "        return {\"status\": \"killed\", \"container_id\": container_id}\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CTO] KILL FAILED: {e} ---\")\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CTO (Agent Spawner) Server] Starting on http://0.0.0.0:5002 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5002)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'cto_server.py' (v2 'Spawner') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q75ESHOXzXih",
        "outputId": "bf150141-12fe-40ba-ec9c-c2caa023c237"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'cto_server.py' (v2 'Spawner') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v2): The \"CEO\" (Agent Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Ports\n",
        "# We just need to know their *future* address\n",
        "CMO_URL = \"http://cmo:5003/run-marketing-plan\"\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    needs_marketing: bool = False\n",
        "\n",
        "async def spawn_agent(client, agent_name, dockerfile, port):\n",
        "    \"\"\"Helper function to call the CTO and spawn an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name,\n",
        "        \"dockerfile_name\": dockerfile,\n",
        "        \"port\": port\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        return spawn_res.json().get(\"container_id\")\n",
        "    return None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Helper function to call the CTO and kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    cmo_container_id = None # To track our \"part-time\" hire\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff (e.g., CMO) ---\n",
        "            if request.needs_marketing:\n",
        "                cmo_container_id = await spawn_agent(client, \"cmo\", \"Dockerfile.cmo\", 5003)\n",
        "                if not cmo_container_id:\n",
        "                    return {\"result\": \"Mission FAILED. Could not hire CMO.\"}\n",
        "\n",
        "                print(\"--- [CEO] CMO is hired. Delegating marketing... ---\")\n",
        "                # We need a longer timeout for the agent to spin up and work\n",
        "                async with httpx.AsyncClient(timeout=300.0) as marketing_client:\n",
        "                    cmo_res = await marketing_client.post(CMO_URL) # Call the newly spawned agent\n",
        "                print(f\"--- [CEO] CMO has reported back: {cmo_res.json()} ---\")\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "\n",
        "            if coo_response.status_code != 200:\n",
        "                return {\"result\": f\"Mission FAILED. COO reported an error.\"}\n",
        "\n",
        "            print(\"--- [CEO] COO has completed the research. ---\")\n",
        "            final_report = coo_response.json()\n",
        "            final_report[\"marketing_status\"] = \"complete\" if cmo_container_id else \"not_requested\"\n",
        "            return final_report\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 4. FIRE \"Part-Time\" Staff (The \"Low Overhead\" Fix) ---\n",
        "        if cmo_container_id:\n",
        "            async with httpx.AsyncClient() as client:\n",
        "                await kill_agent(client, cmo_container_id)\n",
        "            print(f\"--- [CEO] CMO has been 'fired'. Container {cmo_container_id} killed. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Agent Manager) Server] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v2 'Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brqu5p_823yL",
        "outputId": "2fd43d54-aaba-4f54-841c-00c125e7f03a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v2 'Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# ----------------------------------------\n",
        "# MASTER BLUEPRINT (v5 - \"Frankenstein 4.0\"): The \"On-Demand\" Swarm\n",
        "# File: docker-compose.yml (REPLACE YOUR OLD ONE)\n",
        "# ----------------------------------------\n",
        "#\n",
        "cat <<EOF > docker-compose.yml\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "\n",
        "  # --- 1. THE \"FULL-TIME\" C-SUITE (The \"Core\") ---\n",
        "  ceo:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.ceo\n",
        "    ports:\n",
        "      - \"5000:5000\" # The \"front door\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - clo\n",
        "      - backend # COO\n",
        "      - cto\n",
        "\n",
        "  clo: # Legal (Guardrail)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.clo\n",
        "    ports:\n",
        "      - \"7999:7999\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  cto: # The \"Agent Spawner\"\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.cto\n",
        "    ports:\n",
        "      - \"5002:5002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "    depends_on:\n",
        "      - executor\n",
        "    # --- THE \"FRANKENSTEIN\" POWER ---\n",
        "    # This gives the CTO container permission to control the Docker \"nervous system\"\n",
        "    volumes:\n",
        "      - /var/run/docker.sock:/var/run/docker.sock\n",
        "\n",
        "  # --- 2. THE \"FULL-TIME\" OPERATIONS (COO & Laborers) ---\n",
        "  backend: # \"COO\" (Chief Operating Officer)\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.backend\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  frontend:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.frontend\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"7860:7860\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  who_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.who_crew\n",
        "    ports:\n",
        "      - \"8001:8001\"\n",
        "    volumes:\n",
        "      - ./chroma_db_lai:/app/chroma_db_lai\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  what_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.what_crew\n",
        "    ports:\n",
        "      - \"8002:8002\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  when_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.when_crew\n",
        "    ports:\n",
        "      - \"8003:8003\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  where_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.where_crew\n",
        "    ports:\n",
        "      - \"8004:8004\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  how_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.how_crew\n",
        "    ports:\n",
        "      - \"8005:8005\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  why_crew:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.why_crew\n",
        "    ports:\n",
        "      - \"8006:8006\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  quantum:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.quantum\n",
        "    ports:\n",
        "      - \"9000:9000\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "  executor:\n",
        "    build:\n",
        "      context: .\n",
        "      dockerfile: Dockerfile.executor\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "    networks:\n",
        "      - frankenstein_net\n",
        "\n",
        "# --- 3. THE \"PART-TIME\" (On-Demand) OFFICERS ---\n",
        "# We *removed* them. They are no longer \"services.\"\n",
        "# They are just \"blueprints\" (Dockerfiles) that the CTO\n",
        "# will build and spawn *on demand*.\n",
        "\n",
        "networks:\n",
        "  frankenstein_net:\n",
        "    driver: bridge\n",
        "EOF\n",
        "\n",
        "# Verify the new blueprint was created\n",
        "echo \"✅ FINAL 'SWARM' v5 'docker-compose.yml' CREATED.\"\n",
        "ls -l docker-compose.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7smyDBPO3Y_A",
        "outputId": "7b392aa0-bec3-4aa5-cbbd-62f3cca594c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FINAL 'SWARM' v5 'docker-compose.yml' CREATED.\n",
            "-rw-r--r-- 1 root root 2815 Nov 24 12:38 docker-compose.yml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "#\n",
        "# Blueprint 11 (v3): The \"CEO\" (Full C-Suite Manager) Code\n",
        "# File: ceo_server.py (REPLACE YOUR OLD ONE)\n",
        "#\n",
        "cat <<EOF > ceo_server.py\n",
        "import uvicorn\n",
        "import httpx\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# --- The CEO's \"Nervous System\" ---\n",
        "# \"Full-time\" (Permanent) Staff\n",
        "COO_URL = \"http://backend:8000/run-research\"\n",
        "CLO_URL = \"http://clo:7999/check-plan\"\n",
        "CTO_SPAWN_URL = \"http://cto:5002/spawn-agent\"\n",
        "CTO_KILL_URL = \"http://cto:5002/kill-agent\"\n",
        "\n",
        "# \"Part-time\" (On-Demand) Staff Directory\n",
        "# This is the \"corporate phonebook\" for the CEO\n",
        "AGENT_DIRECTORY = {\n",
        "    \"cmo\": {\"port\": 5003, \"dockerfile\": \"Dockerfile.cmo\", \"endpoint\": \"/run-marketing-plan\"},\n",
        "    \"chro\": {\"port\": 5004, \"dockerfile\": \"Dockerfile.chro\", \"endpoint\": \"/run-hr-plan\"},\n",
        "    \"cio\": {\"port\": 5005, \"dockerfile\": \"Dockerfile.cio\", \"endpoint\": \"/run-it-plan\"},\n",
        "    \"csco\": {\"port\": 5006, \"dockerfile\": \"Dockerfile.csco\", \"endpoint\": \"/run-supply-chain-plan\"},\n",
        "    \"cco\": {\"port\": 5007, \"dockerfile\": \"Dockerfile.cco\", \"endpoint\": \"/run-comms-plan\"},\n",
        "    \"cso\": {\"port\": 5008, \"dockerfile\": \"Dockerfile.cso\", \"endpoint\": \"/run-sustainability-plan\"},\n",
        "    \"cdo\": {\"port\": 5009, \"dockerfile\": \"Dockerfile.cdo\", \"endpoint\": \"/run-diversity-plan\"},\n",
        "}\n",
        "\n",
        "class MissionRequest(BaseModel):\n",
        "    topic: str\n",
        "    plan: str\n",
        "    # The CEO can now be told to hire *any* officer\n",
        "    required_officers: List[str] = []\n",
        "\n",
        "# --- Helper Functions (The \"CEO's EA\") ---\n",
        "async def spawn_agent(client, agent_name):\n",
        "    \"\"\"Calls the CTO to spawn an agent from the directory.\"\"\"\n",
        "    if agent_name not in AGENT_DIRECTORY:\n",
        "        print(f\"--- [CEO] ERROR: Unknown agent: {agent_name} ---\")\n",
        "        return None, None\n",
        "\n",
        "    config = AGENT_DIRECTORY[agent_name]\n",
        "    print(f\"--- [CEO] Requesting CTO to spawn {agent_name}... ---\")\n",
        "    spawn_res = await client.post(CTO_SPAWN_URL, json={\n",
        "        \"agent_name\": agent_name,\n",
        "        \"dockerfile_name\": config[\"dockerfile\"],\n",
        "        \"port\": config[\"port\"]\n",
        "    })\n",
        "    if spawn_res.status_code == 200 and spawn_res.json().get(\"status\") == \"spawned\":\n",
        "        container_id = spawn_res.json().get(\"container_id\")\n",
        "        # Return the new agent's address and container ID\n",
        "        return f\"http://{agent_name}:{config['port']}{config['endpoint']}\", container_id\n",
        "    return None, None\n",
        "\n",
        "async def kill_agent(client, container_id):\n",
        "    \"\"\"Calls the CTO to kill an agent.\"\"\"\n",
        "    print(f\"--- [CEO] Requesting CTO to kill container {container_id}... ---\")\n",
        "    await client.post(CTO_KILL_URL, json={\"container_id\": container_id})\n",
        "\n",
        "# --- The \"C-Suite\" Mission Endpoint ---\n",
        "@app.post(\"/execute-mission\")\n",
        "async def execute_mission(request: MissionRequest):\n",
        "    print(f\"--- [CEO] Mission Received: {request.topic} ---\")\n",
        "    # This list will track all \"part-time\" hires to \"fire\" them later\n",
        "    hired_agents: Dict[str, str] = {} # {container_id: agent_name}\n",
        "    mission_results = {}\n",
        "\n",
        "    try:\n",
        "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "\n",
        "            # --- 1. \"AWAIT PERMISSION\" (Talk to CLO) ---\n",
        "            print(\"--- [CEO] Seeking CLO (Legal) approval... ---\")\n",
        "            clo_response = await client.post(CLO_URL, json={\"plan\": request.plan})\n",
        "            if clo_response.status_code != 200 or not clo_response.json().get(\"approved\"):\n",
        "                return {\"result\": f\"Mission REJECTED by CLO: {clo_response.json().get('reason')}\"}\n",
        "            print(\"--- [CEO] CLO (Legal) has APPROVED. ---\")\n",
        "            mission_results[\"clo_approval\"] = clo_response.json()\n",
        "\n",
        "            # --- 2. HIRE \"Part-Time\" Staff (Dynamic Spawning) ---\n",
        "            for agent_name in request.required_officers:\n",
        "                if agent_name in AGENT_DIRECTORY:\n",
        "                    url, container_id = await spawn_agent(client, agent_name)\n",
        "                    if not container_id:\n",
        "                        return {\"result\": f\"Mission FAILED. Could not hire {agent_name}.\"}\n",
        "\n",
        "                    hired_agents[container_id] = agent_name\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} is hired. Delegating task... ---\")\n",
        "\n",
        "                    # Call the newly spawned agent\n",
        "                    async with httpx.AsyncClient(timeout=300.0) as agent_client:\n",
        "                        agent_res = await agent_client.post(url) # Call the new agent\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} has reported back. ---\")\n",
        "                    mission_results[f\"{agent_name}_report\"] = agent_res.json()\n",
        "                else:\n",
        "                    print(f\"--- [CEO] WARNING: No officer in directory named '{agent_name}' ---\")\n",
        "\n",
        "            # --- 3. EXECUTE (Talk to \"Full-Time\" COO) ---\n",
        "            print(f\"--- [CEO] Delegating research to COO (backend:8000)... ---\")\n",
        "            async with httpx.AsyncClient(timeout=900.0) as research_client: # 15 min\n",
        "                coo_response = await research_client.post(COO_URL, json={\"topic\": request.topic, \"plan\": request.plan})\n",
        "\n",
        "            if coo_response.status_code != 200:\n",
        "                return {\"result\": \"Mission FAILED. COO reported an error.\"}\n",
        "\n",
        "            print(\"--- [CEO] COO has completed the research. ---\")\n",
        "            mission_results[\"coo_report\"] = coo_response.json().get(\"result\")\n",
        "            mission_results[\"status\"] = \"Mission Accomplished\"\n",
        "            return mission_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [CEO] CRITICAL MISSION FAILURE: {e} ---\")\n",
        "        return {\"result\": f\"Mission FAILED: {e}\"}\n",
        "\n",
        "    finally:\n",
        "        # --- 4. FIRE \"Part-Time\" Staff (The \"Low Overhead\" Fix) ---\n",
        "        if hired_agents:\n",
        "            print(f\"--- [CEO] Mission complete. 'Firing' {len(hired_agents)} part-time officers... ---\")\n",
        "            async with httpx.AsyncClient() as client:\n",
        "                for container_id, agent_name in hired_agents.items():\n",
        "                    await kill_agent(client, container_id)\n",
        "                    print(f\"--- [CEO] {agent_name.upper()} 'fired'. Container {container_id} killed. ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- [CEO (Full Manager) Server v3] Starting on http://0.0.0.0:5000 ---\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n",
        "EOF\n",
        "\n",
        "echo \"✅ Blueprint 'ceo_server.py' (v3 'Full C-Suite Manager') CREATED.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V53qK5Zx4CIy",
        "outputId": "862af4db-7fcc-48fa-d2ee-8111c95ec163"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blueprint 'ceo_server.py' (v3 'Full C-Suite Manager') CREATED.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmMf_j_17ATa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}